[{
 "title" : "Interactive Reconstruction of Monte Carlo Image Sequences using a Recurrent Denoising Autoencoder", 
 "author" : ["Chakravarty Reddy Alla Chaitanya", "Anton Kaplanyan", "Christoph Schied", "Marco Salvi", "Aaron Lefohn", "Derek Nowrouzezahrai", "Timo Aila"],
 "booktitle" : "ACM Transactions on Graphics (*SIGGRAPH*)", 
 "year" : 2017, 
 "thumbnail" : "images/dnn_denoise_icon.jpg", 
 "image" : "images/dnn_denoise_teaser.png", 
 "additionalmarkup" : "<h3 style=color:red>Presented at SIGGRAPH</h3>",
 "abstract" : "We describe a machine learning technique for reconstructing image se- quences rendered using Monte Carlo methods. Our primary focus is on reconstruction of global illumination with extremely low sampling budgets at interactive rates. Motivated by recent advances in image restoration with deep convolutional networks, we propose a variant of these networks better suited to the class of noise present in Monte Carlo rendering. We allow for much larger pixel neighborhoods to be taken into account, while also improving execution speed by an order of magnitude. Our primary contri- bution is the addition of recurrent connections to the network in order to drastically improve temporal stability for sequences of sparsely sampled input images. Our method also has the desirable property of automatically modeling relationships based on auxiliary per-pixel input channels, such as depth and normals. We show signi cantly higher quality results compared to existing methods that run at comparable speeds, and furthermore argue a clear path for making our method run at realtime rates in the near future.",
  "bibtex": "@article{chaitanya:2017:dnn,\n TITLE = {{Interactive Reconstruction of Monte Carlo Image Sequences using a Recurrent Denoising Autoencoder}},\n AUTHOR = {Chakravarty Reddy Alla Chaitanya and Anton Kaplanyan and Christoph Schied and Marco Salvi and Aaron Lefohn and Derek Nowrouzezahrai and Timo Aila},\n JOURNAL = {{ACM Transactions on Graphics}},\n PUBLISHER = {{Association for Computing Machinery}},\n YEAR = {2017},\n MONTH = Aug }", 
 "linktypes" : ["Paper", "News"],
 "links" : ["files/TBD.pdf", "https://blogs.nvidia.com/blog/2017/05/10/ai-for-ray-tracing/"]
},
{
 "title" : "Antialiasing Complex Global Illumination Effects in Path-space", 
 "author" : ["Laurent Belcour", "Ling-Qi Yan", "Ravi Ramamoorthi", "Derek Nowrouzezahrai"],
 "booktitle" : "ACM Transactions on Graphics (*TOG*)", 
 "year" : 2017, 
 "thumbnail" : "images/gi_filtering_icon.png", 
 "image" : "images/gi_filtering_2017_teaser.png", 
 "additionalmarkup" : "<h3 style=color:red>Presented at SIGGRAPH</h3>",
 "abstract" : "We present the first method to efficiently predict antialiasing footprints to pre-filter color-, normal-, and displacement-mapped appearance in the context of multi-bounce global illumination. We derive Fourier spectra for radiance and importance functions that allow us to compute spatial-angular filtering footprints at path vertices, for both uni- and bi-directional path construction. We then use these footprints to antialias reflectance modulated by high-resolution maps (such as color and normal maps) encountered along a path. In doing so, we also unify the traditional path-space formulation of light-transport with our frequency-space interpretation of global illumination pre-filtering. Our method is fully compatible with all existing single bounce pre-filtering appearance models, not restricted by path length, and easy to implement atop existing path-space renderers. We illustrate its effectiveness on several radiometrically complex scenarios where previous approaches either completely fail or require orders of magnitude more time to arrive at similarly high-quality results.",
  "bibtex": "@article{belcour:hal-01200710,\n TITLE = {{Antialiasing Complex Global Illumination Effects in Path-space}},\n AUTHOR = {Belcour, Laurent and Yan, Ling-Qi and Ramamoorthi, Ravi and Nowrouzezahrai, Derek},\n URL = {https://hal.archives-ouvertes.fr/hal-01200710},\n JOURNAL = {{ACM Transactions on Graphics}},\n PUBLISHER = {{Association for Computing Machinery}},\n VOLUME = {36},\n NUMBER = {1},\n YEAR = {2017},\n MONTH = Jan,\n DOI = {10.1145/2990495},\n PDF = {https://hal.archives-ouvertes.fr/hal-01200710/file/paper.pdf},\n HAL_ID = {hal-01200710},\n HAL_VERSION = {v2},\n }", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/gi_filtering_2017.pdf", "https://www.youtube.com/watch?v=_Sh8xcspWG8"]
},
{
 "title" : "Frequency Based Radiance Cache for Rendering Animations", 
 "author" : ["Renaud Adrien Dubouchet", "Laurent Belcour", "Derek Nowrouzezahrai"],
 "booktitle" : "Eurographics Symposium on Rendering (EGSR)", 
 "year" : 2017, 
 "thumbnail" : "images/ADIIP_icon.png", 
 "image" : "images/ADIIP_teaser.png", 
 "additionalmarkup" : "",
 "abstract" : "We propose a method to render animation sequences with direct distant lighting that only shades a fraction of the total pixels. We leverage frequency-based analyses of light transport to determine shading and image sampling rates across an animation using a samples cache. To do so, we derive frequency bandwidths that account for the complexity of distant lights, visibility, BRDF, and temporal coherence during animation. We finaly apply a cross-bilateral filter when rendering our final images from sparse sets of shading points placed according to our frequency-based oracles (generally less than 25% of the pixels, per frame).",
 "bibtex": "@inproceedings{dubouchet17cache,\n author = {Renaud Adrien Dubouchet and Laurent Belcour and Derek Nowrouzezahrai},\n title = {Frequency Based Radiance Cache for Rendering Animations},\n booktitle = {Proceedings of EGSR (Experimental Ideas & Implementations)},\n year = {2017},\n month = jun,\n publisher = {The Eurographics Association}\n }", 
 "linktypes" : ["Paper"],
 "links" : ["files/ADIIP.pdf"]
},
{
 "title" : "Extended Path Integral Formulation for Volumetric Transport", 
 "author" : ["Toshiya Hachisuka", "Iliyan Georgiev", "Wojciech Jarosz", "Jaroslav Krivanek", "Derek Nowrouzezahrai"],
 "booktitle" : "Eurographics Symposium on Rendering (EGSR)", 
 "year" : 2017, 
 "thumbnail" : "images/uvps_icon.png", 
 "image" : "images/uvps_teaser.png", 
 "additionalmarkup" : "",
 "abstract" : "We propose an extension of the path integral formulation amenable to the expression of volumetric light transport with photon beam estimates. Our main contribution is a generalization of Hachisuka et al.’s [2012] extended path space formulation to light transport in participating media. Our formulation supports various point- and beam-based volumetric density estimators, unifying them with path integration in the spirit of the work by Křivánek et al. [2014]. One unique and useful property of our formulation is that it recasts beam-based density estimation as Monte Carlo path vertex sampling in a higher-dimensional space, rather than beam merging in a lower-dimensional space, which enables a practical algorithm for beam estimators with 3D-blur kernels. We thus establish a complementary theoretical foundation for the development of rendering algorithms using points, beams, and paths in participating media.",
 "bibtex": "@inproceedings{hachisuka17extended,\n author = {Toshiya Hachisuka and Iliyan Georgiev and Wojciech Jarosz and Jaroslav Krivanek and Derek Nowrouzezahrai},\n title = {Extended Path Integral Formulation for Volumetric Transport},\n booktitle = {Proceedings of EGSR (Experimental Ideas & Implementations)},\n year = {2017},\n month = jun,\n }", 
 "linktypes" : ["Paper"],
 "links" : ["files/uvps.pdf"]
},
{
 "title" : "Gradient-Domain Vertex Connection and Merging", 
 "author" : ["Weilun Sun", "Xin Sun", "Nathan Carr", "Derek Nowrouzezahrai", "Ravi Ramamoorthi"],
 "booktitle" : "Eurographics Symposium on Rendering (EGSR)", 
 "year" : 2017, 
 "thumbnail" : "images/GDVCM_icon.png", 
 "image" : "images/GDVCM_teaser.png", 
 "additionalmarkup" : "",
 "abstract" : "Recently, gradient-domain rendering techniques have shown great promise in reducing Monte Carlo noise and improving over- all rendering efficiency. However, all existing gradient-domain methods are built exclusively on top of Monte Carlo integration or density estimation. While these methods can be effective, combining Monte Carlo integration and density estimation has been shown (in the primal domain) to more robustly handle a wider variety of light paths from arbitrarily complex scenes. We present gradient-domain vertex connection and merging (G-VCM), a new gradient-domain technique motivated by primal domain VCM. Our method enables robust gradient sampling in the presence of complex transport, such as specular-diffuse-specular paths, while retaining the denoising power and fast convergence of gradient-domain bidirectional path tracing. We show that G-VCM is able to handle a variety of scenes that exhibit slow convergence when rendered with previous gradient-domain methods.",
 "bibtex": "@inproceedings{sun17gdvcm,\n author = {Weilun Sun and Xin Sun and Nathan A. Carr and Derek Nowrouzezahrai and Ravi Ramamoorthi},\n title = {Gradient-Domain Vertex Connection and Merging},\n booktitle = {Proceedings of EGSR (Experimental Ideas & Implementations)},\n year = {2017},\n month = jun,\n publisher = {The Eurographics Association}\n }", 
 "linktypes" : ["Paper"],
 "links" : ["files/gdvcm.pdf"]
},
{
 "title" : "Gradient-Domain Photon Density Estimation", 
 "author" : ["Binh-Son Hua", "Adrien Gruson", "Derek Nowrouzezahrai", "Toshiya Hachisuka"],
 "booktitle" : "Eurographics (*CGF*)", 
 "year" : 2017, 
 "thumbnail" : "images/GPM_icon.png", 
 "image" : "images/GPM_teaser.png", 
 "additionalmarkup" : "",
 "abstract" : "The most common solutions to the light transport problem rely on either Monte Carlo (MC) integration or density estimation methods, such as uni- & bi-directional path tracing or photon mapping. Recent gradient-domain extensions of MC approaches show great promise; here, gradients of the final image are estimated numerically (instead of the image intensities themselves) with coherent paths generated from a deterministic shift mapping. We extend gradient-domain approaches to light transport simulation based on density estimation. As with previous gradient-domain methods, we detail important considerations that arise when moving from a primal- to gradient-domain estimator. We provide an efficient and straightforward solution to these problems. Our solution supports stochastic progressive density estimation, so it is robust to complex transport effects. We show that gradient-domain photon density estimation converges faster than its primal-domain counterpart, as well as being generally more robust than gradient-domain uni- & bi-directional path tracing for scenes dominated by complex transport.",
 "bibtex": "@article {Hua:2017:GDPM,\n journal = {Computer Graphics Forum},\n title = {{Gradient-Domain Photon Density Estimation}},\n author = {Hua, Binh-Son and Gruson, Adrien and Nowrouzezahrai, Derek and Hachisuka, Toshiya},\n year = {2017},\n publisher = {The Eurographics Association and John Wiley & Sons Ltd.},\n ISSN = {1467-8659},\n DOI = {10.1111/cgf.13104}\n }", 
 "linktypes" : ["Paper", "Slides (PPTX)", "Online Viewer", "Code"],
 "links" : ["files/2017_GradientPM_Hua.pdf", "files/presentation_GPM.pptx", "https://dl.dropboxusercontent.com/u/37606091/research/2017_gpm/comparison/index.html", "https://github.com/gradientpm/gpm"]
},
{
 "title" : "Real-Time Global Illumination using Precomputed Light Field Probes", 
 "author" : ["Morgan McGuire", "Michael Mara", "Derek Nowrouzezahrai", "David Luebke"],
 "booktitle" : "Interactive 3D Graphics &amp; Games (*I3D*)", 
 "year" : 2017, 
 "thumbnail" : "images/McGuire2017LightField_icon.png", 
 "image" : "images/McGuire2017LightField_teaser.png", 
 "additionalmarkup" : "<h3 style=color:red>Best Presentation Award!</h3>",
 "abstract" : "We introduce a new data structure and algorithms that employ it to compute real-time global illumination from static environments. Light field probes encode a scene's full light field and internal visibility. They extend current radiance and irradiance probe structures with per-texel visibility information similar to a G-buffer and variance shadow map. We apply ideas from screen-space and voxel cone tracing techniques to this data structure to efficiently sample radiance on world space rays, with correct visibility information, directly within pixel and compute shaders. From these primitives, we then design two GPU algorithms to efficiently gather real-time, viewer-dependent global illumination onto both static and dynamic objects. These algorithms make different tradeoffs between performance and accuracy. Supplemental GLSL source code is included.",
 "bibtex": "@inproceedings{McGuire2017LightField,\n author = {Morgan McGuire and Michael Mara and Derek Nowrouzezahrai and David Luebke},\n title = {Real-Time Global Illumination using Precomputed Light Field Probes},\n month = {February},\n booktitle = {I3D 2017},\n day = {25},\n year = {2017},\n pages = {11},\n url = {http://graphics.cs.williams.edu/papers/LightFieldI3D17}\n }", 
 "linktypes" : ["Paper", "Slides (I3D)", "Slides (GDC)", "Video", "Code"],
 "links" : ["files/McGuire2017LightField.pdf", "files/McGuire2017LightField-I3DSlides.pdf", "files/McGuire2017LightField-GDCSlides.pdf", "files/McGuire2017LightField.mp4", "files/McGuire2017LightField-Code.zip"]
},
{
 "title" : "Ballistic Shadow Art", 
 "author" : ["Xiaozhong Chen", "Sheldon Andrews", "Paul Kry", "Derek Nowrouzezahrai"],
 "booktitle" : "Graphics Interface", 
 "year" : 2017, 
 "thumbnail" : "images/bashart_icon.png", 
 "image" : "images/bashart_teaser.png", 
 "additionalmarkup" : "",
 "abstract" : "We present a framework for generating animated shadow art using occluders under ballistic motion. We apply a stochastic optimization to find the parameters of a multi-body physics simulation that produce a desired shadow at a specific instant in time. We perform simulations across many different initial conditions, applying a set of carefully crafted energy functions to evaluate the motion trajectory and multi-body shadows. We select the optimal parameters, resulting in a ballistics simulation that produces ephemeral shadow art. Users can design physically-plausible dynamic artwork that would be extremely challenging if even possible to achieve manually. We present and analyze a number of compelling examples.",
 "bibtex": "@proceedings {ballisticshadows17,\n author = {Chen, Xiaozhong and Andrews, Sheldon and Nowrouzezahrai, Derek and Kry, Paul G.},\n title = {{Ballistic Shadow Art}},\n booktitle = {Proceedings of Graphics Interface 2017},\n series = {GI'17},\n year = {2017},\n publisher = {Canadian Human Computer Interaction Society}\n }", 
 "linktypes" : ["Paper", "Slides (PPTX)", "Video"],
 "links" : ["files/bashart_2017.pdf", "files/bashart_GI2017_compressed.pptx", "https://www.youtube.com/watch?v=3-Xc0jutzCQ"]
},
{
 "title" : "Reduced Aggregate Scattering Operators for Path Tracing", 
 "author" : ["Adrian Blumer", "Jan Novak", "Ralf Habel", "Derek Nowrouzezahrai", "Wojciech Jarosz"],
 "booktitle" : "Computer Graphics Forum (Pacific Graphics)", 
 "year" : 2016, 
 "thumbnail" : "images/blumer16reduced_icon.png", 
 "image" : "images/blumer16reduced_teaser.png", 
 "additionalmarkup" : "",
 "abstract" : "Aggregate scattering operators (ASOs) describe the overall scattering behavior of an asset (i.e., an object or volume, or collection thereof) accounting for all orders of its internal scattering. We propose a practical way to precompute and compactly store ASOs and demonstrate their ability to accelerate path tracing. Our approach is modular avoiding costly and inflexible scene-dependent precomputation. This is achieved by decoupling light transport within and outside of each asset, and precomputing on a per-asset level. We store the internal transport in a reduced-dimensional subspace tailored to the structure of the asset geometry, its scattering behavior, and typical illumination conditions, allowing the ASOs to maintain good accuracy with modest memory requirements. The precomputed ASO can be reused across all instances of the asset and across multiple scenes. We augment ASOs with functionality enabling multi-bounce importance sampling, fast short-circuiting of complex light paths, and compact caching, while retaining rapid progressive preview rendering. We demonstrate the benefits of our ASOs by efficiently path tracing scenes containing many instances of objects with complex inter-reflections or multiple scattering.",
  "bibtex": "@article{blumer16reduced,\n author = {Adrian Blumer and Jan Novák and Ralf Habel and Derek Nowrouzezahrai and Wojciech Jarosz},\n title = {Reduced Aggregate Scattering Operators for Path Tracing},\n journal = {Computer Graphics Forum (Proceedings of Pacific Graphics)},\n volume = {35},\n number = {7},\n year = {2016},\n month = oct,\n doi = {10.1111/cgf.13043}\n}", 
 "linktypes" : ["Paper", "Slides (PDF)", "Slides (PPTX)", "Video", "Online Viewer"],
 "links" : ["files/blumer16reduced.pdf", "files/blumer16reduced-slides.pdf", "files/blumer16reduced-slides.pptx", "blumer16reduced.mp4", "https://www.cs.dartmouth.edu/~wjarosz/publications/blumer16reduced-image-comparison/"]
},
{
 "title" : "A Non-Parametric Factor Microfacet Model for Isotropic BRDFs", 
 "author" : ["Mahdi M. Bagher", "John Snyder", "Derek Nowrouzezahrai"],
 "booktitle" : "ACM Transactions on Graphics (*TOG*)", 
 "year" : 2016, 
 "thumbnail" : "images/BRDFFactorFitting_icon.png", 
 "image" : "images/BRDFFactorFitting_teaser.png", 
 "additionalmarkup" : "<h3 style=color:red>To be presented at SIGGRAPH</h3>",
 "abstract" : "We investigate the expressiveness of the microfacet model for isotropic BRDFs measured from real materials by introducing a non-parametric factor model that represents the model's functional structure but abandons restricted parametric formulations of its factors. We propose a new objective based on compressive weighting that controls rendering error in high dynamic range BRDF fits better than previous factorization approaches. We develop a simple numerical procedure to minimize this objective and handle dependencies that arise between microfacet factors. Our method faithfully captures a more comprehensive set of materials than previous state-of-the-art parametric approaches, yet remains compact (3.2KB per BRDF). We experimentally validate the benefit of the microfacet model over a naive orthogonal factorization, and show that fidelity for diffuse materials is modestly improved by fitting an unrestricted shadowing/masking factor. We also compare against a recent data-driven factorization approach [Bilgili et al. 2011] and show that our microfacet-based representation improves rendering accuracy for most materials while reducing storage by more than 10x.",
  "bibtex": "@article{ Bagher:2016:NPFMM,\n author = {Mahdi M. Bagher and John Snyder and Derek Nowrouzezahrai},\n title = {A Non-Parametric Factor Microfacet Model for Isotropic BRDFs},\n journal = {ACM Transactions on Graphics},\n volume = {36},\n number = {6},\n year = {2016},\n month = aug,\n}", 
 "linktypes" : ["Paper", "WebGL Demo", "Comprehensive Analysis (WARNING: <b>1.2GB file</b>)"],
 "links" : ["files/BRDFFactorFitting.pdf", "files/NonParamBRDF/NonParamBRDFDemo.html", "files/supplement.pdf"]
},
{
 "title" : "Deep G-Buffers for Stable Global Illumination Approximation", 
 "author" : ["Michael Mara", "Mogan McGuire", "Derek Nowrouzezahrai", "David Luebke"],
 "booktitle" : "High Performance Graphics (*HPG*)", 
 "year" : 2016, 
 "thumbnail" : "images/DeepGBuffer_icon.png", 
 "image" : "images/DeepGBuffer_teaser.png", 
 "additionalmarkup" : "",
 "abstract" : "We introduce a new hardware-accelerated method for constructing Deep G-buffers that is 2x-8x faster than the previous depth peeling method and produces more stable results. We then build several high-performance shading algorithms atop our representation, including dynamic diffuse interreflection, ambient occlusion (AO), and mirror reflection effects. Our construction method s order-independent, guarantees a minimum separation between layers, operates in a (small) bounded memory footprint, and does not require per-pixel sorting. Moreover, addressing the increasingly expensive cost of pre-rasterization, our approach requires only a single pass over the scene geometry. Our global illumination algorithms approach the speed of the fastest screen-space AO-only techniques while significantly exceeding their quality: we capture small-scale details and complex radiometric effects more robustly than screen-space techniques, and we implicitly handle dynamic illumination conditions. We include the pseudocode for our Deep G-buffer construction in the paper and the full source code of our technique in our supplemental document.",
  "bibtex": "@inproceedings{Mara2016DeepGBuffer,\n  author = {Michael Mara and Morgan McGuire and Derek Nowrouzezahrai and David Luebke}\n  title = {Deep G-Buffers for Stable Global Illumination Approximation},\n  month = {June},\n  day = {24},\n  year = {2016},\n  numpages = {11},\n  booktitle = {HPG},\n  url = {http://graphics.cs.williams.edu/papers/DeepGBuffer16}\n}", 
 "linktypes" : ["Paper", "Video (YouTube)", "Code (108MB)"],
 "links" : ["files/Mara2016DeepGBuffer.pdf", "https://www.youtube.com/watch?v=FOifsDM65s0", "http://graphics.cs.williams.edu/papers/DeepGBuffer16/Mara2016DeepGBuffersDemo.zip"]
},
{
 "title" : "Surface Turbulence for Particle-Based Liquid Simulations", 
 "author" : ["Olivier Mercier", "Cynthia Beauchemin", "Nils Thuerey", "Theodore Kim", "Derek Nowrouzezahrai"],
 "booktitle" : "ACM Transactions on Graphics (SIGGRAPH Asia)", 
 "year" : 2015, 
 "thumbnail" : "images/surface_waves_icon.png", 
 "image" : "images/surface_waves_teaser.png", 
 "additionalmarkup" : "",
 "abstract" : "We present a method to increase the apparent resolution of particlebased liquid simulations. Our method first outputs a dense, temporally coherent, regularized point set from a coarse particle-based liquid simulation. We then apply a surface-only Lagrangian wave simulation to this high-resolution point set. We develop novel methods for seeding and simulating waves over surface points, and use them to generate high-resolution details. We avoid error-prone surface mesh processing, and robustly propagate waves without the need for explicit connectivity information. Our seeding strategy combines a robust curvature evaluation with multiple bands of seeding oscillators, injects waves with arbitrarily fine-scale structures, and properly handles obstacle boundaries. We generate detailed fluid surfaces from coarse simulations as an independent post-process that can be applied to most particle-based fluid solvers.",
  "bibtex": "@article{ Mercier:2015:SW,\n author = {Olivier Mercier and Cynthia Beauchemin and Nils Thuerey and Theodore Kim and Derek Nowrouzezahrai},\n title = {Surface Turbulence for Particle-Based Liquid Simulations},\n journal = {ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH Asia 2015)},\n volume = {34},\n number = {6},\n year = {2015},\n month = nov,\n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/surfaceWaves.pdf", "files/surfaceWaves42.avi"]
},
{
 "title" : "Antialiasing Complex Global Illumination Effects in Path-space", 
 "author" : ["Laurent Belcour", "Ling-Qi Yan", "Ravi Ramamoorthi", "Derek Nowrouzezahrai"],
 "booktitle" : "University of Montreal Technical Report #1375", 
 "year" : 2015, 
 "thumbnail" : "images/gi_filtering_icon.png", 
 "image" : "images/gi_filtering_teaser.png", 
 "additionalmarkup" : "",
 "abstract" : "We present the first method to efficiently and accurately predict antialiasing footprints to pre-filter color-, normal-, and displacement-mapped appearance in the context of multi-bounce global illumination. We derive Fourier spectra for radiance and importance functions that allow us to compute spatial-angular filtering footprints at path vertices, for both uni- and bi-directional path construction. We then use these footprints to antialias reflectance modulated by high-resolution color, normal, and displacement maps encountered along a path. In doing so, we also unify the traditional path-space formulation of light-transport with our frequency-space interpretation of global illumination pre-filtering. Our method is fully compatible with all existing single bounce pre-filtering appearance models, not restricted by path length, and easy to implement atop existing path-space renderers. We illustrate its effectiveness on several radiometrically complex scenarios where previous approaches either completely fail or require orders of magnitude more time to arrive at similarly high-quality results.",
  "bibtex": "@article{Belcour:2015:GIF,\nauthor = {Laurent Belcour and Ling-Qi Yan and Ravi Ramamoorthi and Derek Nowrouzezahrai},\ntitle = {Antialiasing Complex Global Illumination Effects in Path-space},\njournal = {University of Montreal Tech Report},\nvolume = {34},\nnumber = {6},\nmonth = dec,\nyear = {2015},\nnumpages = {14},\npublisher = {ACM},\naddress = {New York, NY, USA},\n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/gi_filtering_paper.pdf", "https://www.youtube.com/watch?t=2&v=_Sh8xcspWG8"]
},
{
 "title" : " State of the Art in Artistic Editing of Appearance, Lighting, and Material", 
 "author" : ["Thorsten-Walther Schmidt", "Fabio Pellacini", "Derek Nowrouzezahrai", "Wojciech Jarosz", "Carsten Dachsbacher"],
 "booktitle" : "Computer Graphics Forum Journal (CGF)", 
 "year" : 2015, 
 "thumbnail" : "images/schmidt14star_icon.jpg", 
 "image" : "images/schmidt14star_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "Mimicking the appearance of the real world is a longstanding goal of computer graphics, with several important applications in the feature-film, architecture and medical industries. Images with well-designed shading are an important tool for conveying information about the world, be it the shape and function of a CAD model, or the mood of a movie sequence. However, authoring this content is often a tedious task, even if undertaken by groups of highly-trained and experienced artists. Unsurprisingly, numerous methods to facilitate and accelerate this appearance editing task have been proposed, enabling the editing of scene objects' appearances, lighting, and materials, as well as entailing the introduction of new interaction paradigms and specialized preview rendering techniques. In this review we provide a comprehensive survey of artistic appearance, lighting, and material editing approaches. We organize this complex and active research area in a structure tailored to academic researchers, graduate students, and industry professionals alike. In addition to editing approaches, we discuss how user interaction paradigms and rendering backends combine to form usable systems for appearance editing. We conclude with a discussion of open problems and challenges to motivate and guide future research.",
  "bibtex": "@article{schmidt16star, author = {Thorsten-Walther Schmidt and Fabio Pellacini and Derek Nowrouzezahrai and Wojciech Jarosz and Carsten Dachsbacher}, title = {State of the Art in Artistic Editing of Appearance, Lighting, and Material}, journal = {Computer Graphics Forum}, volume = {35}, number = {1}, year = {2016}, month = feb, pages = {216–233}, doi = {10.1111/cgf.12721}, keywords = {artistic editing, appearance editing, material design, lighting design, relighting, material appearance, artistic control} }", 
 "linktypes" : ["Paper"],
 "links" : ["files/schmidt15star.pdf"]
},
{
 "title" : " Proceedings of the Eurographics Symposium on Rendering", 
 "author" : ["Jaakko Lehtinen", "Derek Nowrouzezahrai"],
 "booktitle" : "Eurographics Symposium on Rendering (EGSR)", 
 "year" : 2015, 
 "thumbnail" : "images/egsr2015_icon.png", 
 "image" : "images/egsr2015_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "This was the 26th annual event in the series of very successful Eurographics Symposia on Rendering and Eurographics Workshops on Rendering. The workshop took place June 23–26, 2015 at the Fraunhofer IGD, Darmstadt, Germany.",
 "bibtex": "@proceedings{egsr2015,\neditor = {Jaakko Lehtinen and Derek Nowrouzezahrai},\ntitle = {Proceedings of the Eurographics Symposium on Rendering 2015},\nseries = {Computer Graphics Forum},\nvolume = {34},\nnumber = {4},\nyear = {2015},\nmonth = jun\n}", 
 "linktypes" : ["External Link"],
 "links" : ["http://diglib.eg.org/handle/10.2312/12634"]
},
{
 "title" : " Efficient and Accurate Spherical Kernel Integrals using Isotropic Decomposition", 
 "author" : ["Cyril Soler", "Mahdi M. Bagher", "Derek Nowrouzezahrai"],
 "booktitle" : "ACM Transactions on Graphics (TOG)", 
 "year" : 2015, 
 "thumbnail" : "images/zh_filtering_icon.jpg", 
 "image" : "images/zh_filtering_teaser.jpg", 
 "additionalmarkup" : "<h3 style=color:red>Presented at SIGGRAPH Asia</h3>",
 "abstract" : "Spherical filtering is fundamental to many problems in image synthesis, such as computing the reflected light over a surface or anti-aliasing mirror reflections over a pixel. This operation is challenging since the profile of spherical filters (e.g., the view-evaluated BRDF or the geometry-warped pixel footprint, above) typically exhibits both spatial- and rotational variation at each pixel, precluding precomputed solutions. We accelerate complex spherical filtering tasks using isotropic spherical decomposition (ISD), decomposing spherical filters into a linear combination of simpler isotropic kernels. Our general ISD is flexible to the choice of the isotropic kernels, and we demonstrate practical realizations of ISD on several problems in rendering: shading and prefiltering with spatially-varying BRDFs, anti-aliasing environment mapped mirror reflections, and filtering of noisy reflectance data. Compared to previous basis-space rendering solutions, our shading solution generates ground truth-quality results at interactive rates, avoiding costly reconstruction and large approximation errors.",
  "bibtex": "@article{Soler:2015:ISD,\nauthor = {Cyril Soler and Mahdi M. Bagher and Derek Nowrouzezahrai},\ntitle = {Efficient and Accurate Spherical Kernel Integrals using Isotropic Decomposition},\njournal = {ACM Transactions on Graphics},\nvolume = {34},\nnumber = {6},\nmonth = dec,\nyear = {2015},\nnumpages = {14},\npublisher = {ACM},\naddress = {New York, NY, USA},\n}", 
 "linktypes" : ["Code", "Paper", "Supplemental", "Video"],
 "links" : ["http://maverick.inria.fr/Membres/Cyril.Soler/RZH/", "files/ZH_filtering_paper.pdf", "files/ZH_filtering_supplemental.pdf", "files/ZH_filtering_video.mp4"]
},
{
 "title" : " High Performance Non-linear Motion Blur", 
 "author" : ["Jean-Philippe Guertin", "Derek Nowrouzezahrai"],
 "booktitle" : "Eurographics Symposium on Rendering (EGSR)", 
 "year" : 2015, 
 "thumbnail" : "images/nonlinear_mb_icon.png", 
 "image" : "images/nonlinear_mb_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "Motion blur is becoming more common in interactive applications such as games and previsualization tools. Here, a common strategy is to approximate motion blur with an image-space post-process, and many recent approaches demonstrate very efficient and high-quality results [Sou13,GMN14]. Unfortunately, all such approaches assume underlying linear motion, and so they cannot approximate non-linear motion blur effects without significant visual artifacts.We present a new motion blur post-process that correctly treats the case of non-linear motion (in addition to linear motion) using an efficient curve-sampling scatter approach. We simulate plausible non-linear motion blur in 4ms at 1920 1080 and our approach has many desirable properties: its cost is independent of geometric complexity, it robustly estimates blurring extents to avoid typical over- and under-blurring artifacts, it supports unlimited motion magnitudes, and it is less noisy than existing techniques.",
  "bibtex": "@inproceedings{Guertin:2015:NLMB,\nbooktitle = {Eurographics Symposium on Rendering - Experimental Ideas & Implementations},\neditor = {Jaakko Lehtinen and Derek Nowrouzezahrai},\ntitle = {{High Performance Non-linear Motion Blur}},\nauthor = {Guertin, Jean-Philippe and Nowrouzezahrai, Derek},\nyear = {2015},\npublisher = {The Eurographics Association},\nDOI = {10.2312/sre.20151171}\n}", 
 "linktypes" : ["Paper"],
 "links" : ["files/nonlinear_mb.pdf"]
},
{
 "title" : " Practical Shading of Height Fields and Meshes using Spherical Harmonic Exponentiation", 
 "author" : ["Aude Giraud", "Derek Nowrouzezahrai"],
 "booktitle" : "Eurographics Symposium on Rendering (EGSR)", 
 "year" : 2015, 
 "thumbnail" : "images/hf_shexp_icon.png", 
 "image" : "images/hf_shexp_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "Interactively computing smooth shading effects from environmental lighting, such as soft shadows and glossy reflections, is a challenge in scenes with dynamic objects. We present a method to efficiently approximate these effects in scenes comprising animating objects and dynamic height fields, additionally allowing interactive manipulation of the view and lighting. Our method extends spherical harmonic (SH) exponentiation approaches to support environmental shadowing from both dynamic blockers and dynamic height field geometry. We also derive analytic expressions for the view-evaluated BRDF, directly in the log-SH space, in order to support diffuse-to-glossy shadowed reflections while avoiding expensive basis-space product operations. We illustrate interactive rendering results using a hybrid, multi-resolution screen- and object-space visibility-marching algorithm that decouples geometric complexity from shading complexity.",
  "bibtex": "@inproceedings{Giraud:2015:HFSHExp,\nbooktitle = {Eurographics Symposium on Rendering - Experimental Ideas & Implementations},\neditor = {Jaakko Lehtinen and Derek Nowrouzezahrai},\ntitle = {{Practical Shading of Height Fields and Meshes using Spherical Harmonic Exponentiation}},\nauthor = {Giraud, Aude and Nowrouzezahrai, Derek},\nyear = {2015},\npublisher = {The Eurographics Association},\nDOI = {10.2312/sre.20151161}\n}", 
 "linktypes" : ["Paper", "Slides"],
 "links" : ["files/hf_shexp.pdf", "files/hf_shexp_slides.pdf"]
},
{
 "title" : " Facial Performance Enhancement Using Dynamic Shape Space Analysis", 
 "author" : ["Amit H. Bermano", "Derek Bradley", "Thabo Beeler", "Fabio Zünd", "Derek Nowrouzezahrai", "Ilya Baran", "Olga Sorkine", "Hanspeter Pfister", "Robert W. Sumner", "Bernd Bickel", "Markus Gross"],
 "booktitle" : " ACM Transactions on Graphics (SIGGRAPH)", 
 "year" : 2014, 
 "thumbnail" : "images/perfupsampling_icon.jpg", 
 "image" : "images/perfupsampling_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "The facial performance of an individual is inherently rich in subtle deformation and timing details. Although these subtleties make the performance realistic and compelling, they often elude both motion capture and hand animation. We present a technique for adding fine-scale details and expressiveness to low-resolution art-directed facial performances, such as those created manually using a rig, via marker-based capture, by fitting a morphable model to a video, or through Kinect reconstruction using recent faceshift technology. We employ a high-resolution facial performance capture system to acquire a representative performance of an individual in which he or she explores the full range of facial expressiveness. From the captured data, our system extracts an expressiveness model that encodes subtle spatial and temporal deformation details specific to that particular individual. Once this model has been built, these details can be transferred to low-resolution artdirected performances. We demonstrate results on various forms of input; after our enhancement, the resulting animations exhibit the same nuances and fine spatial details as the captured performance, with optional temporal enhancement to match the dynamics of the actor. Finally, we show that our technique outperforms the current state-of-the-art in example-based facial animation. ",
  "bibtex": "@article{Bermano:2014:FPE,\ntitle =     {Facial Performance Enhancement Using Dynamic Shape Space Analysis},\nauthor =    {Amit H. Bermano and Derek Bradley and Thabo Beeler and Fabio Zünd and Derek Nowrouzezahrai and Ilya Baran and Olga Sorkine and Hanspeter Pfister and Robert W. Sumner and Bernd Bickel and Markus Gross},\nyear =      {2014},\njournal =   {ACM Transactions on Graphics},\n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/Facial-Performance-Enhancement.pdf", "files/Facial-Performance-Enhancement.mp4"]
},
{
 "title" : " A Fast and Stable Feature-Aware Motion Blur Filter", 
 "author" : ["Jean-Philippe Guertin", "Morgan McGuire", "Derek Nowrouzezahrai"],
 "booktitle" : " High-Performance Graphics (*HPG*)", 
 "year" : 2014, 
 "thumbnail" : "images/tiledmb_icon.jpg", 
 "image" : "images/tiledmb_teaser.png", 
 "additionalmarkup" : "<h3 style=color:red>Our work was <a style=\"color:red;\" href = \"https://github.com/keijiro/KinoMotion\">implemented</a> as a Unity plug-in!</h3>", 
 "abstract" : "High-quality motion blur is an increasingly important effect in interactive graphics however, even in the context of offline rendering, it is often approximated as a post process. Recent motion blur post-processes (e.g., [MHBO12, Sou13]) generate plausible results with interactive performance, however distracting artifacts still remain in the presence of e.g. overlapping motion or large- and fine-scale motion features. We address these artifacts with a more robust sampling and filtering scheme with only a small additional runtime cost. We render plausible, temporally-coherent motion blur on several complex animation sequences, all in under 2ms at a resolution 1280 x 720. Moreover, our filter is designed to integrate seamlessly with post-process anti-aliasing and depth of field. ",
  "bibtex": "@inproceedings{Guertin2014MotionBlur,\n  author = {Jean-Philippe Guertin and Morgan McGuire and Derek Nowrouzezahrai},\n  title = {A Fast and Stable Feature-Aware Motion Blur Filter},  month = {June},\n  day = {24},\n  year = {2014},\n  pages = {10},\n  booktitle = {HPG},\n  publisher = {ACM\/Eurographics},\n  url = {http:\/\/graphics.cs.williams.edu\/papers\/MotionBlurHPG14}\n}", 
 "linktypes" : ["Paper", "Video", "YouTube"],
 "links" : ["files/Guertin2014MotionBlur.pdf", "files/Guertin2014MotionBlur.mp4", "https://www.YouTube.com/watch?v=OqpHWDgfnoc"]
},
{
 "title" : " Fast Global Illumination Approximations on Deep G-Buffers", 
 "author" : ["Michael Mara", "Morgan McGuire", "Derek Nowrouzezahrai", "David Luebke"],
 "booktitle" : " NVIDIA Technical Report", 
 "year" : 2014, 
 "thumbnail" : "images/FastLayeredGI_icon.jpg", 
 "image" : "images/FastLayeredGI_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "Deep Geometry Buffers (G-buffers) combine the fine-scale and efficiency of screen-space data with much of the robustness of voxels. We introduce a new hardware-aware method for computing two-layer deep G-buffers and show how to produce dynamic indirect radiosity, ambient occlusion (AO), and mirror reflection from them in real-time. Our illumination computation approaches the performance of todayâ€™s screen-space AO-only rendering passes on current GPUs and far exceeds their quality. Our G-buffer generation method is order-independent, guarantees a minimum separation between layers, operates in a (small) bounded memory footprint, and avoids any sorting. Moreover, to address the increasingly expensive cost of pre-rasterization computations, our approach requires only a single pass over the scene geometry. We show how to apply Monte Carlo sampling and reconstruction to these to efficiently compute global illumination terms from the deep G-buffers. The resulting illumination captures small-scale detail and dynamic illumination effects and is more substantially more robust than screen space estimates. It necessarily still view-dependent and lower-quality than offline rendering. However, it is real-time, temporally coherent, and plausible based on visible geometry. Furthermore, the lighting algorithms automatically identify undersampled areas to fill from broad-scale or precomputed illumination. All techniques described are both practical today for real-time rendering and designed to scale with near-future hardware architecture and content trends. We include pseudocode for deep G-buffer generation, and source code and a demo for the global illumination sampling and filtering. ",
  "bibtex": "@techreport{Mara2014DeepGBuffer,\n  author = {Michael Mara and Morgan McGuire and Derek Nowrouzezahrai  and David Luebke}\n  title = {Fast Global Illumination Approximations on Deep G-Buffers},\n  month = {June},\n  day = {16},\n  year = {2014},\n  pages = {16},\n  institution = {NVIDIA Corporation},\n  number = {NVR-2014-001},\n  url = {http://graphics.cs.williams.edu/papers/DeepGBuffer14}\n}", 
 "linktypes" : ["Paper", "Video", "YouTube", "Code/Demo"],
 "links" : ["files/Mara2014DeepGBuffer.pdf", "files/Mara2014DeepGBuffer.mp4", "https://www.YouTube.com/watch?v=SXEDMv6VaSc", "files/Mara2014DeepGBufferDemo.zip"]
},
{
 "title" : " State of the Art in Artistic Editing of Appearance, Lighting, and Material", 
 "author" : ["Thorsten-Walther Schmidt", "Fabio Pellacini", "Derek Nowrouzezahrai", "Wojciech Jarosz", "Carsten Dachsbacher"],
 "booktitle" : " Eurographics - State of the Art Report (*STAR*)", 
 "year" : 2014, 
 "thumbnail" : "images/schmidt14star_icon.jpg", 
 "image" : "images/schmidt14star_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "Mimicking the appearance of the real world is a longstanding goal of computer graphics, with several important applications in the feature-film, architecture and medical industries. Images with well-designed shading are an important tool for conveying information about the world, be it the shape and function of a CAD model, or the mood of a movie sequence. However, authoring this content is often a tedious task, even if undertaken by groups of highly-trained and experienced artists. Unsurprisingly, numerous methods to facilitate and accelerate this appearance editing task have been proposed, enabling the editing of scene objects' appearances, lighting, and materials, as well as entailing the introduction of new interaction paradigms and specialized preview rendering techniques. In this review we provide a comprehensive survey of artistic appearance, lighting, and material editing approaches. We organize this complex and active research area in a structure tailored to academic researchers, graduate students, and industry professionals alike. In addition to editing approaches, we discuss how user interaction paradigms and rendering backends combine to form usable systems for appearance editing. We conclude with a discussion of open problems and challenges to motivate and guide future research.",
  "bibtex": "@inproceedings{schmidt14star,\nauthor = {Thorsten-Walther Schmidt and Fabio Pellacini and Derek Nowrouzezahrai and Wojciech Jarosz and Carsten Dachsbacher},\ntitle = {State of the Art in Artistic Editing of Appearance, Lighting, and Material},\nbooktitle = {Eurographics 2014 - State of the Art Reports},\nyear = {2014},\nmonth = apr,\npublisher = {Eurographics Association},\naddress = {Strasbourg, France},\nkeywords = {relighting, material appearance, artistic control}\n}", 
 "linktypes" : ["Paper"],
 "links" : ["files/schmidt14star.pdf"]
},
{
 "title" : " Visibility Silhouettes for Semi-Analytic Spherical Integration", 
 "author" : ["Derek Nowrouzezahrai", "Ilya Baran", "Kenny Mitchell", "Wojciech Jarosz"],
 "booktitle" : " Computer Graphics Forum Journal", 
 "year" : 2014, 
 "thumbnail" : "images/vissil_icon.jpg", 
 "image" : "images/vissil_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "At each shade point, the spherical visibility function encodes occlusion from surrounding geometry, in all directions. Computing this function is difficult and point-sampling approaches, such as ray-tracing or hardware shadow mapping, are traditionally used to efficiently approximate it. We propose a semi-analytic solution to the problem where the spherical silhouette of the visibility is computed using a search over a 4D dual mesh of the scene. Once computed, we are able to semi-analytically integrate visibility-masked spherical functions along the visibility silhouette, instead of over the entire hemisphere. In this way, we avoid the artefacts that arise from using point-sampling strategies to integrate visibility, a function with unbounded frequency content. We demonstrate our approach on several applications, including direct illumination from realistic lighting and computation of pre-computed radiance transfer data. Additionally, we present a new frequency-space method for exactly computing all-frequency shadows on diffuse surfaces. Our results match ground truth computed using importance-sampled stratified Monte Carlo ray-tracing, with comparable performance on scenes with low-to-moderate geometric complexity. ",
  "bibtex": "@article {nowrouzezahrai13visibility,\n author = {Nowrouzezahrai, Derek and Baran, Ilya and Mitchell, Kenny and Jarosz, Wojciech},\n title = {Visibility Silhouettes for Semi-Analytic Spherical Integration},\n journal = {Computer Graphics Forum},\n issn = {1467-8659},\n url = {http:\/\/dx.doi.org\/10.1111\/cgf.12257},\n doi = {10.1111\/cgf.12257},\n pages = {{{n/a--n/a}}},\n keywords = {all-frequency shadowing, image-based rendering, spherical visibility},\n year = {2013},\n }", 
 "linktypes" : ["External Paper Link", "Video"],
 "links" : ["http://onlinelibrary.wiley.com/doi/10.1111/cgf.12257/abstract/", "files/vissil.mp4"]
},
{
 "title" : " Unifying Points, Beams, and Paths in Volumetric Light Transport Simulation", 
 "author" : ["Jaroslav Křivánek", "Iliyan Georgiev", "Toshiya Hachisuka", "Petr Vévoda", "Martin Šik", "Derek Nowrouzezahrai", "Wojciech Jarosz"],
 "booktitle" : "ACM Transactions on Graphics (SIGGRAPH)", 
 "year" : 2014, 
 "thumbnail" : "images/unifying_icon.jpg", 
 "image" : "images/unifying_teaser.jpg", 
 "additionalmarkup" : "<h3 style=color:red><a style=\"color:red;\" href = \"http://vcg.isti.cnr.it/cgf/winner.php\">Winner</a> of the CGF Cover Image Competition!</h3>", 
 "abstract" : "Efficiently computing light transport in participating media in a manner that is robust to variations in media density, scattering albedo, and anisotropy is a difficult and important problem in realistic image synthesis. While many specialized rendering techniques can efficiently resolve subsets of transport in specific volumetric media, no single approach can robustly handle all types of effects. To combat this problem we unify volumetric density estimation, using point- and beam-estimates, and Monte Carlo-based solutions to the path-integral formulation of the rendering and radiative transport equations. We generalize multiple importance sampling to correctly handle combinations of these fundamentally different classes of radiance estimators. This in turn allows us to develop a single rendering algorithm that correctly combines the benefits (and mediates the limitations) of these powerful volume rendering techniques. ",
  "bibtex": "@article{Krivanek:2014:UPB,\nauthor = {K{\\v{r}}iv{'{a}}nek, Jaroslav and Georgiev, Iliyan and Toshiya Hachisuka and Petr V{'e}voda and Martin {\\v{S}}ik and Derek Nowrouzezahrai and Wojciech Jarosz},\ntitle      = {Unifying points, beams, and paths in volumetric light transport simulation},\njournal    = {ACM Trans. Graph.},\nvolume = {33},\nnumber = {4},\nmonth = aug,\nyear = {2014},\nissn = {0730-0301},\npages = {1--13},\nnumpages = {13},\npublisher = {ACM},\naddress = {New York, NY, USA},\n}", 
 "linktypes" : ["Paper", "Poster", "Derivation", "Image Comparison 1", "2", "3", "ICTT Abstract"],
 "links" : ["files/upbp-paper.pdf", "files/2014-upbp-poster.pdf", "files/upbp-supplemental.pdf", "http://cgg.mff.cuni.cz/~jaroslav/papers/2014-upbp/still%20life-comparison-html/compare.html", "http://cgg.mff.cuni.cz/~jaroslav/papers/2014-upbp/mirrorballs-comparison-html/compare.html", "http://cgg.mff.cuni.cz/~jaroslav/papers/2014-upbp/bathroom-comparison-html/compare.html", "files/upbp-ictt24.pdf"]
},
{
 "title" : " Error analysis of estimators that use combinations of stochastic sampling strategies for direct illumination", 
 "author" : ["Kartic Subr", "Derek Nowrouzezahrai", "Wojciech Jarosz", "Jan Kautz", "Kenny Mitchell"],
 "booktitle" : " Eurographics Symposium on Rendering (*EGSR*)", 
 "year" : 2014, 
 "thumbnail" : "images/FourierIS_icon.jpg", 
 "image" : "images/FourierIS_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "We present a theoretical analysis of error of combinations of Monte Carlo estimators used in image synthesis. Importance sampling and multiple importance sampling are popular variance-reduction strategies. Unfortunately, neither strategy improves the rate of convergence of Monte Carlo integration. Jittered sampling (a type of stratified sampling), on the other hand is known to improve the convergence rate. Most rendering software optimistically combine importance sampling with jittered sampling, hoping to achieve both. We derive the exact error of the combination of multiple importance sampling with jittered sampling. In addition, we demonstrate a further benefit of introducing negative correlations (antithetic sampling) between estimates to the convergence rate. As with importance sampling, antithetic sampling is known to reduce error for certain classes of integrands without affecting the convergence rate. In this paper, our analysis and experiments reveal that importance and antithetic sampling, if used judiciously and in conjunction with jittered sampling, may improve convergence rates. We show the impact of such combinations of strategies on the convergence rate of estimators for direct illumination. ",
  "bibtex": "@article{SNJKM14,\n  author = {Kartic Subr and Derek Nowrouzezahrai and Wojciech Jarosz and Jan Kautz and Kenny Mitchell},\n  title = {Error analysis of estimators that use combinations of stochastic sampling strategies for direct illumination},\n  journal = {Computer Graphics Forum 33(4) (Proceedings of Eurographics Symposium on Rendering 2014)},\n  year = {2014},\n  volume = {33},\n  number = {4},\n}", 
 "linktypes" : ["Paper"],
 "links" : ["files/sva_egsr.pdf"]
},
{
 "title" : " A Fast and Stable Feature-Aware Motion Blur Filter (TR Version)", 
 "author" : ["Jean-Philippe Guertin", "Morgan McGuire", "Derek Nowrouzezahrai"],
 "booktitle" : " NVIDIA Technical Report", 
 "year" : 2013, 
 "thumbnail" : "images/tiledmb_icon.jpg", 
 "image" : "images/tiledmb_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "High-quality motion blur is an increasingly important and pervasive effect in interactive graphics that, even in the context of offline rendering, is often approximated using a post process. Recent motion blur post-process filters (e.g., {{[MHBO12, Sou13]}}) efficiently generate plausible results suitable for modern interactive rendering pipelines. However, these approaches may produce distracting artifacts, for instance, when different motions overlap in depth or when both large- and fine-scale features undergo motion. We address these artifacts with a more robust sampling and filtering scheme that incurs only small additional runtime cost. We render plausible, temporally-coherent motion blur on several complex animation sequences, all in just 3ms at a resolution 1280x720. Moreover, our filter is designed to integrate seamlessly with post-process anti-aliasing and depth of field. ",
  "bibtex": "@techreport{Guertin2013MotionBlurReport,\n  author = {Jean-Philippe Guertin and Morgan McGuire and Derek Nowrouzezahrai},\n  title = {A Fast and Stable Feature-Aware Motion Blur Filter},\n  month = {November},\n  day = {26},\n  year = {2013},\n  pages = {10},\n  institution = {NVIDIA Corporation},\n  number = {NVR-2013-003}\n }", 
 "linktypes" : ["Paper", "Video", "YouTube"],
 "links" : ["files/Guertin2013MotionBlur.pdf", "files/Guertin2013MotionBlur.mp4", "http://youtu.be/T30xXGvzTZ0"]
},
{
 "title" : " State of the Art in Photon Density Estimation", 
 "author" : ["Toshiya Hachisuka", "Wojciech Jarosz", "Iliyan Georgiev", "Anton S. Kaplanyan", "Derek Nowrouzezahrai"],
 "booktitle" : " Courses at *ACM SIGGRAPH Asia*", 
 "year" : 2013, 
 "thumbnail" : "images/starphoton_icon.jpg", 
 "image" : "images/starphoton_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "Photon density estimation techniques are a popular choice for simulating light transport in scenes with complicated geometry and materials. This class of algorithms can be used to accurately simulate inter-reflections, caustics, color bleeding, scattering in participating media, and subsurface scattering. Since its introduction, photon density estimation has been significantly extended in computer graphics with the introduction of: specialized techniques that intelligently modify the positions or bandwidths to reduce visual error using a small number of photons, approaches which eliminate error completely in the limit, methods that use higher-order samples and queries to reduce error in participating media, and recent generalized formulations that bridge the gap between photon density estimation and other techniques. This course provides the necessary insight to implement all these latest advances in photon density estimation. The course starts out with a short introduction to photon density estimation using classical photon mapping, but the remainder of the two-part course provides hands-on explanations of the latest developments in this area by the experts behind each technique. The course will give the audience concrete and practical understanding of the latest developments in photon density estimation techniques that have not been presented in prior similar SIGGRAPH/SIGGRAPH Asia courses. ",
  "bibtex": "@inproceedings{Hachisuka:2013:StarPM,\n author = {Toshiya Hachisuka and Wojciech Jarosz and Iliyan Georgiev and Anton Kaplanyan and Derek Nowrouzezahrai},\n title = {State of the Art in Photon Density Estimation},\n booktitle = {ACM SIGGRAPH Asia 2013 Courses},\n series = {SIGGRAPH Asia '13},\n year = {2013},\n location = {Hong Kong, China},\n publisher = {ACM},\n address = {New York, NY, USA}\n}", 
 "linktypes" : ["Website"],
 "links" : ["http://users-cs.au.dk/toshiya/starpm2013a/"]
},
{
 "title" : " The Shading Probe: Fast Appearance Acquisition for Mobile AR", 
 "author" : ["Dan A. Calian", "Kenny Mitchell", "Derek Nowrouzezahrai", "Jan Kautz"],
 "booktitle" : " SIGGRAPH Asia Technical Briefs", 
 "year" : 2013, 
 "thumbnail" : "images/shadingProbe_icon.jpg", 
 "image" : "images/shadingProbe_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "The ubiquity of mobile devices with powerful processors and integrated video cameras is re-opening the discussion on practical augmented reality (AR). Despite this technological convergence, several issues prevent reliable and immersive AR on these platforms. We address one such problem, the shading of virtual objects and determination of lighting that remains consistent with the surrounding environment. We design a novel light probe and exploit its structure to permit an efficient reformulation of the rendering equation that is suitable for fast shading on mobile devices. Unlike prior approaches, our shading probe directly captures the shading, and not the incident light, in a scene. As such, we avoid costly and unreliable radiometric calibration as well as side-stepping the need for complex shading algorithms. Moreover, we can tailor the shading probe's structure to better handle common lighting scenarios, such as outdoor settings. We achieve high-performance shading of virtual objects in an AR context, incorporating plausible local global illumination effects, on mobile platforms. ",
  "bibtex": "@article{calian2013shadingprobe,\n author = {Dan Andrei Calian, Kenny Mitchell, Derek Nowrouzezahrai, Jan Kautz},\n title = {The Shading Probe: Fast Appearance Acquisition for Mobile AR},\n year = {2013},\n journal = {Proceedings of ACM SIGGRAPH Asia Technical Briefs},\n month = {to appear},\n number = {6},\n url = {http://dx.doi.org/10.1145/2508363.2524695},\n volume = {32},\n}", 
 "linktypes" : ["Paper"],
 "links" : ["files/shadingProbe.pdf"]
},
{
 "title" : " Path-Space Manipulation of Physically-Based Light Transport", 
 "author" : ["Thorsten-Walther Schmidt", "Jan Novak", "Johannes Meng", "Anton S. Kaplanyan", "Tim Reiner", "Derek Nowrouzezahrai", "Carsten Dachsbacher"],
 "booktitle" : " ACM Transactions on Graphics~(SIGGRAPH)", 
 "year" : 2013, 
 "thumbnail" : "images/PathManip_icon.jpg", 
 "image" : "images/PathManip_teaser.png", 
 "additionalmarkup" : "<h3 style=color:red><a style=\"color:red;\" href=\"http://www.lightrig.de\">Lightrig</a> spin-off company</h3>", 
 "abstract" : "Industry-quality content creation relies on tools for lighting artists to quickly prototype, iterate, and refine final renders. As industryleading studios quickly adopt physically-based rendering (PBR) across their art generation pipelines, many existing tools have become unsuitable as they address only simple effects without considering underlying PBR concepts and constraints. We present a novel light transport manipulation technique that operates directly on path-space solutions of the rendering equation. We expose intuitive direct and indirect manipulation approaches to edit complex effectssuch as (multi-refracted) caustics, diffuse and glossy indirect bounces, and direct / indirect shadows. With our sketch- and objectspace selection, all built atop a parameterized regular expression engine, artists can search and isolate shading effects to inspect and edit. We classify and filter paths on the fly and visualize the selected transport phenomena. We survey artists who used our tool to manipulate complex phenomena on both static and animated scenes. ",
  "bibtex": "@article{schmidt13,\n    author = {Thorsten-Walther Schmidt and Jan Novak and Johannes Meng and Anton S. Kaplanyan and Tim Reiner and Derek Nowrouzezahrai and Carsten Dachsbacher},\n    title = {Path-Space Manipulation of Physically-Based Light Transport},\n    journal = {ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH 2013)},\n    volume = {32},\n    number = {4},\n    year = {2013},\n    month = aug,,\n    numpages = {8},\n}", 
 "linktypes" : ["Paper"],
 "links" : ["files/LTM.pdf"]
},
{
 "title" : " Image-Based Reconstruction and Synthesis of Dense Foliage", 
 "author" : ["Derek Bradley", "Derek Nowrouzezahrai", "Paul Beardsley"],
 "booktitle" : " ACM Transactions on Graphics~(SIGGRAPH)", 
 "year" : 2013, 
 "thumbnail" : "images/Leaves_icon.jpg", 
 "image" : "images/Leaves_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "Flora is an element in many computer-generated scenes. But trees, bushes and plants have complex geometry and appearance, and are difficult to model manually. One way to address this is to capture models directly from the real world. Existing techniques have focused on extracting macro structure such as the branching structure of trees, or the structure of broad-leaved plants with a relatively small number of surfaces. This paper presents a finer scale technique to demonstrate for the first time the processing of densely leaved foliage - computation of 3D structure, plus extraction of statistics for leaf shape and the configuration of neighboring leaves. Our method starts with a mesh of a single exemplar leaf of the target foliage. Using a small number of images, point cloud data is obtained from multi-view stereo, and the exemplar leaf mesh is fitted non-rigidly to the point cloud over several iterations. Initialization of the fitting is done using RANSAC, making it robust to outliers in the stereo reconstruction and suitable for the chaotic point cloud obtained from foliage. In addition, our method learns a statistical model of leaf shape and appearance during the reconstruction phase, and a model of the transformations between neighboring leaves. This information can subsequently be used to generate a variety of plausible leaves for that plant species in plausible configuration, and is useful in two ways - to augment and increase leaf density in reconstructions of captured foliage, and to synthesize new foliage that conforms to a user-specified layout and density. The result of our technique is a dense set of captured leaves with realistic appearance, and a method for leaf synthesis. Our approach excels at reconstructing plants and bushes that are primarily defined by dense leaves and is demonstrated with multiple examples. ",
  "bibtex": "@article{bradley13,\n    author = {Derek Bradley and Derek Nowrouzezahrai and Paul Beardsley},\n    title = {Image-Based Reconstruction and Synthesis of Dense Foliage},\n    journal = {ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH 2013)},\n    volume = {32},\n    number = {4},\n    year = {2013},\n    month = aug,,\n    numpages = {10},\n}", 
 "linktypes" : ["Paper"],
 "links" : ["files/LeavesPaper.pdf"]
},
{
 "title" : " Filtering Non-Linear Transfer Functions on Surfaces", 
 "author" : ["Eric Heitz", "Derek Nowrouzezahrai", "Pierre Poulin", "Fabrice Neyret"],
 "booktitle" : " IEEE Trans. on Visualization and CG (*TVCG*)", 
 "year" : 2013, 
 "thumbnail" : "images/Filter_icon.jpg", 
 "image" : "images/Filter_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "Applying non-linear transfer functions and look-up tables to procedural functions (such as noise), surface attributes, or even surface geometry are common strategies used to enhance visual detail. Their simplicity and ability to mimic a wide range of realistic appearances have led to their adoption in many rendering problems. As with any textured or geometric detail, proper filtering is needed to reduce aliasing when viewed across a range of distances, but accurate and efficient transfer function filtering remains an open problem for several reasons: transfer functions are complex and non-linear, especially when mapped through procedural noise and/or geometry-dependent functions, and the effects of perspective and masking further complicate the filtering over a pixel's footprint. We accurately solve this problem by computing and sampling from specialized filtering distributions on the fly, yielding very fast performance. We investigate the case where the transfer function to filter is a color map applied to (macroscale) surface textures (like noise), as well as color maps applied according to (microscale) geometric details. We introduce a novel representation of a (potentially modulated) color map's distribution over pixel footprints using Gaussian statistics and, in the more complex case of high-resolution color mapped microsurface details, our filtering is view- and light-dependent, and capable of correctly handling masking and occlusion effects. Our approach can be generalized to filter other physical-based rendering quantities. We propose an application to shading with irradiance environment maps over large terrains. Our framework is also compatible with the case of transfer functions used to warp surface geometry, as long as the transformations can be represented with Gaussian statistics, leading to proper view- and light-dependent filtering results. Our results match ground truth and our solution is well suited to real-time applications, requires only a few lines of shader code (provided in supplemental material), is high performance, and has a negligible memory footprint. ",
  "bibtex": "@article{heitz:hal-00876432,\n AUTHOR = {Heitz, Eric and Nowrouzezahrai, Derek and Poulin, Pierre and Neyret, Fabrice},\n TITLE = {{Filtering Non-Linear Transfer Functions on Surfaces}},\n JOURNAL = {{IEEE Transactions on Visualization and Computer Graphics}},\n PUBLISHER = {IEEE Computer Society},\n YEAR = {2013},\n MONTH = Nov,\n DOI = {10.1109/TVCG.2013.102},\nURL = {http://hal.inria.fr/hal-00876432}\n}", 
 "linktypes" : ["Paper", "Supplement", "Video"],
 "links" : ["files/heitz_tvcg.pdf", "files/heitz_tvcg_supplemental.pdf", "files/heitz_tvcg_video.mp4"]
},
{
 "title" : " Filtering Color Mapped Textures and Surfaces", 
 "author" : ["Eric Heitz", "Derek Nowrouzezahrai", "Pierre Poulin", "Fabrice Neyret"],
 "booktitle" : "Symp. on Interactive 3D Graphics &amp; Games (*I3D*)", 
 "year" : 2013, 
 "thumbnail" : "images/FilterI3D_icon.jpg", 
 "image" : "images/FilterI3D_teaser.png", 
 "additionalmarkup" : "<h3 style=color:red>Winner: Best paper award!</h3>", 
 "abstract" : "Color map textures applied directly to surfaces, to geometric microsurface details, or to procedural functions (such as noise), are commonly used to enhance visual detail. Their simplicity and ability to mimic a wide range of realistic appearances have led to their adoption in many rendering problems. As with any textured or geometric detail, proper filtering is needed to reduce aliasing when viewed across a range of distances, but accurate and efficient color map filtering remains an open problem for several reasons: color maps are complex non-linear functions, especially when mapped through procedural noise and/or geometry-dependent functions, and the effects of perspective and masking further complicate the filtering over a pixel's footprint. We accurately solve this problem by computing and sampling from specialized filtering distributions on-thefly, yielding very fast performance. We filter color map textures applied to (macro-scale) surfaces, as well as color maps applied according to (micro-scale) geometric details. We introduce a novel representation of a (potentially modulated) color map's distribution over pixel footprints using Gaussian statistics and, in the more complex case of high-resolution color mapped microsurface details, our filtering is view- and light-dependent, and capable of correctly handling masking and occlusion effects. Our results match ground truth and our solution is well suited to real-time applications, requires only a few lines of shader code (provided in supplemental material), is high performance, and has a negligible memory footprint. ",
  "bibtex": "@inproceedings{Heitz2013,\n author = {Heitz, Eric and Nowrouzezahrai, Derek and Poulin, Pierre and Neyret, Fabrice},\n title = {Filtering Color Mapped Textures and Surfaces},\n booktitle = {ACM Siggraph Symposium on Interactive 3D Graphics and Games},\n year = {2013},\n publisher = {ACM},\n address = {New York, NY, USA},\n }", 
 "linktypes" : ["Paper", "Supplement"],
 "links" : ["files/heitz2013filtercolordisplacement.pdf", "files/heitz2013filtercolordisplacement-supplemental.pdf"]
},
{
 "title" : " Joint Importance Sampling of Low-Order Volumetric Scattering", 
 "author" : ["Iliyan Georgiev", "Jaroslav Křivánek", "Toshiya Hachisuka", "Derek Nowrouzezahrai", "Wojciech Jarosz"],
 "booktitle" : " ACM Transactions on Graphics~(SIGGRAPH Asia)", 
 "year" : 2013, 
 "thumbnail" : "images/georgiev13joint_icon.jpg", 
 "image" : "images/georgiev13joint_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "Central to all Monte Carlo-based rendering algorithms is the construction of light transport paths from the light sources to the eye. Existing rendering approaches sample path vertices incrementally when constructing these light transport paths. Paths should ideally be constructed according to a joint probability density function proportional to the integrand, yet current incremental sampling strategies only locally account for certain terms in the integrand. The resulting probability density is thus a product of the conditional densities of each local sampling step, constructed without explicit control over the form of the final joint distribution of the complete path. We analyze why current incremental construction schemes often lead to high variance in the presence of participating media, and reveal that such approaches are an unnecessary legacy inherited from traditional surface-based rendering algorithms. We devise joint importance sampling of path vertices in participating media to construct paths that explicitly account for the product of all scattering and geometry terms along a sequence of vertices instead of just locally at a single vertex. This leads to a number of practical importance sampling routines to explicitly construct single- and double-scattering subpaths in anisotropically-scattering media. We demonstrate the benefit of our new sampling techniques, integrating them into several path-based rendering algorithms such as path tracing, bidirectional path tracing, and many-light methods. We also use our sampling routines to generalize deterministic shadow connections to connection subpaths consisting of two or three random decisions, to efficiently simulate higher-order multiple scattering. Our algorithms significantly reduce noise and increase performance in renderings with both isotropic and highly anisotropic, low-order scattering. ",
  "bibtex": "@article{georgiev13joint,\n    author = {Iliyan Georgiev and Jaroslav Křivánek and Toshiya Hachisuka and Derek Nowrouzezahrai and Wojciech Jarosz},\n    title = {Joint Importance Sampling of Low-Order Volumetric Scattering},\n    journal = {ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH Asia 2013)},\n    volume = {32},\n    number = {6},\n    year = {2013},\n    month = nov,\n    keywords = {photon beams, virtual ray lights, virtual beam lights, VRLs, VBLs, path tracing, bidirectional path tracing}\n}", 
 "linktypes" : ["Paper", "Interactive Image Comparison 1", "2"],
 "links" : ["files/georgiev13joint.pdf", "http://www.iliyan.com/publications/JointPathSampling/comparison/", "http://zurich.disneyresearch.com/~wjarosz/publications/georgiev13joint-image-comparison.html"]
},
{
 "title" : " The Magic Lens: Refractive Steganography", 
 "author" : ["Marios Papas", "Thomas Houit", "Derek Nowrouzezahrai", "Markus Gross", "Wojciech Jarosz"],
 "booktitle" : " ACM Transactions on Graphics (SIGGRAPH Asia)", 
 "year" : 2012, 
 "thumbnail" : "images/lens_icon.jpg", 
 "image" : "images/lens_teaser.jpg", 
 "additionalmarkup" : "<h3 style=color:red>Featured on Proceedings Back Cover and Papers Fast Forward Video!</h3>", 
 "abstract" : "We present an automatic approach to design and manufacture passive display devices based on optical hidden image decoding. Motivated by classical steganography techniques we construct Magic Lenses, composed of refractive lenslet arrays, to reveal hidden images when placed over potentially unstructured printed or displayed source images. We determine the refractive geometry of these surfaces by formulating and efficiently solving an inverse light transport problem, taking into account additional constraints imposed by physical manufacturing processes. We fabricate several variants on the basic magic lens idea including using a single source image to encode several hidden images which are only revealed when the lens is placed at prescribed rotational orientations or viewed from different angles. We also present an important special case, the universal lens, that forms an injunction with the source image grid and can be applied to arbitrary source images. We use this type of lens to generate hidden animation sequences. We validate our simulation results with many real-world manufactured magic lenses, and experiment with two separate manufacturing processes. ",
  "bibtex": "@article{ papas12magic, \nauthor = {Marios Papas and Thomas Houit and Derek Nowrouzezahrai and Markus Gross and Wojciech Jarosz}, \ntitle = {The Magic Lens: Refractive Steganography}, \njournal = {ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH Asia 2012)}, \nvolume = {31}, \nnumber = {6}, \nyear = {2012}, \n}", 
 "linktypes" : ["Paper", "Supplement", "YouTube)"],
 "links" : ["files/papas12magic.pdf", "files/papas12magic-supplemental.pdf", "http://www.YouTube.com/watch?v=XvIZvhJlEXU"]
},
{
 "title" : " Progressive Virtual Beam Lights", 
 "author" : ["Jan Novak", "Derek Nowrouzezahrai", "Carsten Dachsbacher", "Wojciech Jarosz"],
 "booktitle" : " Eurographics Symposium on Rendering (EGSR)", 
 "year" : 2012, 
 "thumbnail" : "images/novak12vbls_icon.jpg", 
 "image" : "images/novak12vbls_teaser.jpg", 
 "additionalmarkup" : "<h3 style=color:red>Featured on Proceedings Back Cover!</h3>", 
 "abstract" : "A recent technique that forms virtual ray lights (VRLs) from path segments in media, reduces the artifacts common to VPL approaches in participating media, however, distracting singularities still remain. We present Virtual Beam Lights (VBLs), a progressive many-lights algorithm for rendering complex indirect transport paths in, from, and to media. VBLs are efficient and can handle heterogeneous media, anisotropic scattering, and moderately glossy surfaces, while provably converging to ground truth. We inflate ray lights into beam lights with finite thicknesses to eliminate the remaining singularities. Furthermore, we devise several practical schemes for importance sampling the various transport contributions between camera rays, light rays, and surface points. VBLs produce artifact-free images faster than VRLs, especially when glossy surfaces and/or anisotropic phase functions are present. Lastly, we employ a progressive thickness reduction scheme for VBLs in order to render results that converge to ground truth. ",
  "bibtex": "@article{novak12vbls,\n    author = {Jan Nov{'a}k and Derek Nowrouzezahrai and Carsten Dachsbacher and Wojciech Jarosz},\n    title = {Progressive Virtual Beam Lights},\n    journal = {Computer Graphics Forum (Proceedings of EGSR 2012)},\n    volume = {31},\n    number = {4},\n    year = {2012},\n    month = jul,\n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/VBL.pdf", "files/VBL.mp4"]
},
{
 "title" : " Virtual Ray Lights for Rendering Scenes with Participating Media", 
 "author" : ["Jan Novak", "Derek Nowrouzezahrai", "Carsten Dachsbacher", "Wojciech Jarosz"],
 "booktitle" : " ACM Transactions on Graphics (SIGGRAPH)", 
 "year" : 2012, 
 "thumbnail" : "images/novak12vrls_icon.jpg", 
 "image" : "images/novak12vrls_teaser.jpg", 
 "additionalmarkup" : "<h3 style=color:red><a style=\"color:red;\" href = \"http://vcg.isti.cnr.it/cgf/winner.php\">Runner-up</a> for CGF Cover Image Competition!</h3>", 
 "abstract" : "We present an efficient many-light algorithm for simulating indirect illumination in, and from, participating media. Instead of creating discrete virtual point lights (VPLs) at vertices of random-walk paths, we present a continuous generalization that places virtual ray lights (VRLs) along each path segment in the medium. Furthermore, instead of evaluating the lighting independently at discrete points in the medium, we calculate the contribution of each VRL to entire camera rays through the medium using an efficient Monte Carlo product sampling technique. We prove that by spreading the energy of virtual lights along both light and camera rays, the singularities that typically plague VPL methods are significantly diminished. This greatly reduces the need to clamp energy contributions in the medium, leading to robust and unbiased volumetric lighting not possible with current many-light techniques. Furthermore, by acting as a form of final gather, we obtain higher-quality multiple-scattering than existing density estimation techniques like progressive photon beams. ",
  "bibtex": "@article{novak12vrls,\n    author = {Jan Nov{'a}k and Derek Nowrouzezahrai and Carsten Dachsbacher and Wojciech Jarosz},\n    title = {Virtual Ray Lights for Rendering Scenes with Participating Media},\n    journal = {ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH 2012)},\n    volume = {31},\n    number = {4},\n    year = {2012},\n    month = jul,\n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/VRL.pdf", "files/VRL.mp4"]
},
{
 "title" : " Sparse Zonal Harmonic Factorization for Efficient SH Rotation", 
 "author" : ["Derek Nowrouzezahrai", "Patricio Simari", "Eugene Fiume"],
 "booktitle" : " ACM Transactions on Graphics (SIGGRAPH)", 
 "year" : 2012, 
 "thumbnail" : "images/ZHF_icon.jpg", 
 "image" : "images/ZHF_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "We present a sparse analytic representation for spherical functions, including those expressed in a spherical harmonic (SH) expansion, that is amenable to fast and accurate rotation on the GPU. Exploiting the fact that each band-l SH basis function can be expressed as a weighted sum of 2l+1 rotated band-l zonal harmonic (ZH) lobes, we develop a factorization that significantly reduces this number. We investigate approaches for promoting sparsity in the change-of-basis matrix, and also introduce lobe sharing to reduce the total number of unique lobe directions used for an order-N expansion from N*N to 2N-1. Our representation does not introduce approximation error, is suitable for any type of spherical function (e.g., lighting or transfer), and requires no offline fitting procedure; only a (sparse) matrix multiplication is required to map to/from SH. We provide code for our rotation algorithms, and apply them to several real-time rendering applications. ",
  "bibtex": "@article{Nowrouzezahrai:2012:ZHF,\n  year = 2012,\n  journal = {ACM Transactions on Graphics},\n  title = {Sparse Zonal Harmonic Factorization for Efficient SH Rotation},\n  author = {Derek Nowrouzezahrai and Patricio Simari and Eugene Fiume},\n}", 
 "linktypes" : ["Paper", "Supplement", "Video"],
 "links" : ["files/SHRot_mine.pdf", "files/supplemental_sketch_ToG.pdf", "files/ZHF_video.mp4"]
},
{
 "title" : " A Theory of Monte Carlo Visibility Sampling", 
 "author" : ["Ravi Ramamoorthi", "John Anderson", "Mark Meyer", "Derek Nowrouzezahrai"],
 "booktitle" : " ACM Transactions on Graphics (SIGGRAPH)", 
 "year" : 2012, 
 "thumbnail" : "images/Ramamoorthi_ATO_icon.jpg", 
 "image" : "images/Ramamoorthi_ATO_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "Soft shadows from area lights are one of the most crucial effects in high quality and production rendering, but Monte Carlo sampling of visibility is often the main source of noise in rendered images. Indeed, it is common to use deterministic uniform sampling for the smoother shading effects in direct lighting, so that all of the Monte-Carlo noise arises from visibility sampling alone. In this paper, we analyze theoretically and empirically, using both statistical and Fourier methods, the effectiveness of different non-adaptive Monte Carlo sampling patterns for rendering soft shadows. We start with a single image scanline and a linear light source, and gradually consider more complex visibility functions at a pixel. We show analytically that the lowest expected variance is in fact achieved by uniform sampling (albeit at the cost of visual banding artifacts). Surprisingly, we show that for two or more discontinuities in the visibility function, a comparable error to uniform sampling is obtained by uniform jitter sampling, where a constant jitter is applied to all samples in a uniform pattern (as opposed to jittering each stratum as in standard stratified sampling). The variance can be reduced by up to a factor of two, compared to stratified or quasi-Monte Carlo techniques, without the banding in uniform sampling. We augment our statistical analysis with a novel 2D Fourier analysis across the pixel-light space. This allows us to characterize the banding frequencies in uniform sampling, and gives insights into the behavior of uniform jitter and stratified sampling. We next extend these results to planar area light sources. We show that the best sampling method can vary, depending on the type of light source (circular, gaussian or square/rectangular). The correlation of adjacent light scanlines in square light sources can reduce the effectiveness of uniform jitter sampling, while the smoother shape of circular and gaussian-modulated sources preserves its benefits - these findings are also exposed through our frequency analysis. In practical terms, the theory in this paper provides guidelines for selecting visibility sampling strategies, which can reduce the number of shadow samples by 20 to 40 percent, with simple modifications to existing rendering code. ",
  "bibtex": "@article{Ramamoorthi:2012:ATO,\n  year = 2012,\n  journal = {ACM Transactions on Graphics},\n  title = {A Theory of Monte Carlo Visibility Sampling},\n  author = {Ravi Ramamoorthi and John Anderson and Mark Meyer and Derek Nowrouzezahrai},\n  url = {http://graphics.berkeley.edu/papers/Ramamoorthi-ATO-2012-02/},\n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/Ramamoorthi-ATO-2012-02.pdf", "files/Ramamoorthi-ATO-2012-02.mp4"]
},
{
 "title" : " Learning Hatching for Pen-and-Ink Illustration of Surfaces", 
 "author" : ["Evangelos Kalogerakis", "Derek Nowrouzezahrai", "Simon Breslav", "Aaron Hertzmann"],
 "booktitle" : " ACM Transactions on Graphics (SIGGRAPH)", 
 "year" : 2012, 
 "thumbnail" : "images/learning_sketches_icon.jpg", 
 "image" : "images/learning_sketches_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "This paper presents an algorithm for learning hatching styles from line drawings. An artist draws a single hatching illustration of a 3D object. Their strokes are analyzed to extract the following per-pixel properties: hatching level (hatching, cross-hatching, or no strokes), stroke orientation, spacing, intensity, length, and thickness. A mapping is learned from input features to these properties, using classification, regression, and clustering techniques. Then, a new illustration can be generated in the artist's style, as follows. First, given a new view of a 3D object, the learned mapping is applied to synthesize target stroke properties for each pixel. A new illustration is then generated by synthesizing hatching strokes according to the target properties. ",
  "bibtex": "@article{Kalogerakis:2011:mlhatching,\n  Author    = {Evangelos Kalogerakis and Derek Nowrouzezahrai and Simon Breslav and Aaron Hertzmann},\n  Title     = {Learning {H}atching for {P}en-and-{I}nk {I}llustration of {S}urfaces},\n  Journal   = {ACM Transactions on Graphics},\n  Volume    = {31},\n  Number    = {1},\n  Year = {2011},\n}", 
 "linktypes" : ["Paper"],
 "links" : ["files/MLHatching.pdf"]
},
{
 "title" : " Delta Radiance Transfer", 
 "author" : ["Bradford Loos", "Derek Nowrouzezahrai", "Wojciech Jarosz", "Peter-Pike Sloan"],
 "booktitle" : " ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (*I3D*)", 
 "year" : 2012, 
 "thumbnail" : "images/DRT_icon.jpg", 
 "image" : "images/DRT_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "Modular Radiance Transfer (MRT) is a recent technique for computing approximate direct-to-indirect transport. Scenes are dynamically constructed by warping and connecting simple shapes and compact transport operators are only precomputed on these simple shapes. MRT ignores fine-scale transport from clutter objects inside the scene, and computes light transport with reduced dimensional operators, which allows extremely high performance but can lead to significant approximation error. We present several techniques to alleviate this limitation, allowing the light transport from clutter in a scene to be accounted for. We derive additional low-rank delta operators to compensate for these missing light transport paths by modeling indirect shadows and interreflections from, and onto, clutter objects in the scene. We retain MRT's scene-independent precomputation and augment its scene-dependent initialization with clutter transport generation, resulting in increased accuracy without a performance penalty. Our implementation is simple, requiring a few small matrix-vector multiplications that generate a delta lightmap added to MRT's output, and does not adversely affect the performance benefits of the overall algorithm. ",
  "bibtex": "@inproceedings{Loos2012,\n author = {Loos, Bradford James and Nowrouzezahrai, Derek and Jarosz, Wojciech and Sloan, Peter-Pike},\n title = {Delta Radiance Transfer},\n booktitle = {ACM Siggraph Symposium on Interactive 3D Graphics and Games},\n year = {2012},\n location = {Costa Mesa, CA},\n publisher = {ACM},\n address = {New York, NY, USA},\n }", 
 "linktypes" : ["Paper", "Video", "YouTube"],
 "links" : ["files/drt.pdf", "files/DRT.mp4", "http://www.YouTube.com/watch?v=gixb_F7yUHc&feature=youtu.be"]
},
{
 "title" : " Manufacturing Layered Attenuators for Multiple Prescribed Shadow Images", 
 "author" : ["Ilya Baran", "Philipp Keller", "Derek Bradley", "Stelian Coros", "Wojciech Jarosz", "Derek Nowrouzezahrai", "Markus Gross"],
 "booktitle" : " Eurographics", 
 "year" : 2012, 
 "thumbnail" : "images/ManufacturingAttenuators_icon.jpg", 
 "image" : "images/ManufacturingAttenuators_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "We present a practical and inexpensive method for creating physical objects that cast different color shadow images when illuminated by prescribed lighting configurations. The input to our system is a number of lighting configurations and corresponding desired shadow images. Our approach computes attenuation masks, which are then printed on transparent materials and stacked to form a single multi-layer attenuator. When illuminated with the input lighting configurations, this multi-layer attenuator casts the prescribed color shadow images. Alternatively, our method can compute layers so that their permutations produce different prescribed shadow images under fixed lighting. Each multi-layer attenuator is quick and inexpensive to produce, can generate multiple full-color shadows, and can be designed to respond to different types of natural or synthetic lighting setups. We illustrate the effectiveness of our multi-layer attenuators in simulation and in reality, with the sun as a light source. ",
  "bibtex": "@article{baran12manufacturing,\n author = {Ilya Baran and Philipp Keller and Derek Bradley and Stelian Coros and Wojciech Jarosz and Derek Nowrouzezahrai and Markus Gross},\n title = {Manufacturing Layered Attenuators for Multiple Prescribed Shadow Images},\n journal = {Computer Graphics Forum (Proceedings of Eurographics 2012)},\n volume = {31},\n number = {2},\n year = {2012},\n month = may,\n note = {accepted for publication}\n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/manufacturingattenuators.pdf", "files/manufacturingattenuators.mp4"]
},
{
 "title" : " Irradiance Rigs", 
 "author" : ["Hong Yuan", "Derek Nowrouzezahrai", "Peter-Pike Sloan"],
 "booktitle" : " Journal of Graphics, GPU, and Game Tools", 
 "year" : 2012, 
 "thumbnail" : "images/rigs_icon.jpg", 
 "image" : "images/rigs_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "When precomputed lighting is generated for static scene elements, the incident illumination on dynamic objects must be computed in a manner that is efficient and that faithfully captures the near- and far-field variation of the environment's illumination. Depending on the relative size of dynamic objects, as well as the number of lights in the scene, previous approaches fail to adequately sample the incident lighting and/or fail to scale. We present a principled, error-driven approach for dynamically transitioning between near- and far-field lighting. A more accurate model for sampling near-field lighting for disk sources is introduced, as well as far-field sampling and interpolation schemes tailored to each dynamic object. Lastly, we apply a flexible reflectance model to the computed illumination. ",
  "bibtex": "@article{ SHN10, \nauthor = {Yuan, Hong and Nowrouzezahrai, Derek and Sloan, Peter-Pike}, \ntitle = {Irradiance Rigs}, \njournal = {Journal of Graphics, GPU, and Game Tools}, \nvolume = {16}, \nnumber = {1}, \nyear = {2012}, \n}", 
 "linktypes" : ["PDF"],
 "links" : ["files/irradiance_rigs_jgt.pdf"]
},
{
 "title" : " A Programmable System for Artistic Volumetric Lighting", 
 "author" : ["Derek Nowrouzezahrai", "Jared Johnson", "Andrew Selle", "Dylan Lacewell", "Michael Kaschalk", "Wojciech Jarosz"],
 "booktitle" : " ACM Transactions on Graphics~(SIGGRAPH)", 
 "year" : 2011, 
 "thumbnail" : "images/artsy_beams_icon.jpg", 
 "image" : "images/artsy_beams_teaser.jpg", 
 "additionalmarkup" : "<h3 style=color:red>Featured on Proceedings Back Cover and in Papers Fast Forward Video!</h3>", 
 "abstract" : "We present a method for generating art-directable volumetric effects, ranging from physically-accurate to non-physical results. Our system mimics the way experienced artists think about volumetric effects by using an intuitive lighting primitive, and decoupling the modeling and shading of this primitive. To accomplish this, we generalize the physically-based photon beams method to allow arbitrarily programmable simulation and shading phases. This provides an intuitive design space for artists to rapidly explore a wide range of physically-based as well as plausible, but exaggerated, volumetric effects. We integrate our approach into a real-world production pipeline and couple our volumetric effects to surface shading. ",
  "bibtex": "@article{nowrouzezahrai11programmable,\n    author = {Derek Nowrouzezahrai and Jared Johnson and Andrew Selle and Dylan Lacewell and Michael Kaschalk and Wojciech Jarosz},\n    title = {A Programmable System for Artistic Volumetric Lighting},\n    journal = {ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH 2011)},\n    volume = {30},\n    number = {4},\n    year = {2011},\n    month = aug,\n    pages = {29:1--29:8},\n    articleno = {29},\n    numpages = {8},\n    issn = {0730-0301}\n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/nowrouzezahrai11programmable.pdf", "files/nowrouzezahrai11programmable.mov"]
},
{
 "title" : " Progressive Photon Beams", 
 "author" : ["Wojciech Jarosz", "Derek Nowrouzezahrai", "Robert Thomas", "Peter-Pike Sloan", "Matthias Zwicker"],
 "booktitle" : " ACM Transactions on Graphics (SIGGRAPH Asia)", 
 "year" : 2011, 
 "thumbnail" : "images/ppb_icon.jpg", 
 "image" : "images/ppb_teaser.jpg", 
 "additionalmarkup" : "<h3 style=color:red>Featured in the Proceedings Inside Cover and the Papers Fast Forward Video!</h3>", 
 "abstract" : "We present progressive photon beams, a new algorithm for rendering complex lighting in participating media. Our technique is efficient, robust to complex light paths, and handles heterogeneous media and anisotropic scattering while provably converging to the correct solution using a bounded memory footprint. We achieve this by extending the recent photon beams variant of volumetric photon mapping. We show how to formulate a progressive radiance estimate using photon beams, providing the convergence guarantees and bounded memory usage of progressive photon mapping. Progressive photon beams can robustly handle situations that are difficult for most other algorithms, such as scenes containing participating media and specular interfaces, with realistic light sources completely enclosed by refractive and reflective materials. Our technique handles heterogeneous media and also trivially supports stochastic effects such as depth-of-field and glossy materials. Finally, we show how progressive photon beams can be implemented efficiently on the GPU as a splatting operation, making it applicable to interactive and real-time applications. These features make our technique scalable, providing the same physically-based algorithm for interactive feedback and reference-quality, unbiased solutions. ",
  "bibtex": "@article{jarosz11progressive,\n    author = {Wojciech Jarosz and Derek Nowrouzezahrai and Robert Thomas and Peter-Pike Sloan and Matthias Zwicker},\n    title = {Progressive Photon Beams},\n    journal = {ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH Asia 2011)},\n    volume = {30},\n    number = {6},\n    year = {2011},\n    month = dec,\n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/jarosz11progressive.pdf", "files/jarosz11progressive.mp4"]
},
{
 "title" : " Wrap Shading", 
 "author" : ["Peter-Pike Sloan", "Derek Nowrouzezahrai", "Hong Yuan"],
 "booktitle" : " Journal of Graphics, GPU, and Game Tools", 
 "year" : 2011, 
 "thumbnail" : "images/wrap_icon.jpg", 
 "image" : "images/wrap_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "Shading models that wrap around the hemisphere have been used to approximate subsurface scattering, area light sources or just as a softer re?ectance model. We present a generalization of a technique that has been successfully used in games and include details on how to incorporate them when lighting using spherical harmonics. ",
  "bibtex": "@article{ SHN10, \nauthor = {Sloan, Peter-Pike and Nowrouzezahrai, Derek and Yuan, Hong}, \ntitle = {Wrap Shading}, \njournal = {Journal of Graphics, GPU, and Game Tools}, \nvolume = {15}, \nnumber = {4}, \nyear = {2010}, \n}", 
 "linktypes" : ["Paper"],
 "links" : ["files/jgt_wrap.pdf"]
},
{
 "title" : " Perceptually-Based Compensation of Light Pollution in Display Systems", 
 "author" : ["Jeroen van Baar", "Steven Poulakos", "Wojciech Jarosz", "Derek Nowrouzezahrai", "Rasmus Tamstorf", "Markus Gross"],
 "booktitle" : " Symp. on Applied Perception in Graphics &amp; Visualization", 
 "year" : 2011, 
 "thumbnail" : "images/dome_icon.jpg", 
 "image" : "images/dome_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "This paper addresses the problem of unintended light contributions due to physical properties of display systems. An example of such unintended contribution is crosstalk in stereoscopic 3D display systems, often referred to as ghosting. Ghosting results in a reduction of visual quality, and may lead to an uncomfortable viewing experience. The latter is due to conflicting (depth) edge cues, which can hinder the human visual system (HVS) proper fusion of stereo images (stereopsis). We propose an automatic, perceptually-based computational compensation framework, which formulates pollution elimination as a minimization problem. Our method aims to distribute the error introduced by the pollution in a perceptually optimal manner. As a consequence ghost edges are smoothed locally, resulting in a more comfortable stereo viewing experience. We show how to make the computation tractable by exploiting the structure of the resulting problem, and also propose a perceptually-based pollution prediction. We show that our general framework is applicable to other light pollution problems, such as descattering. ",
  "bibtex": "@inproceedings{vanbaar11perceptually,\n    author = {Jeroen van Baar and Steven Poulakos and Wojciech Jarosz and Derek Nowrouzezahrai and Rasmus Tamstorf and Markus Gross},\n    title = {Perceptually-Based Compensation of Light Pollution in Display Systems},\n    booktitle = {Proceedings of the 2011 ACM Symposium on Applied Perception in Graphics and Visualization},\n    year = {2011},\n    month = aug,\n    publisher = {ACM},\n    address = {New York, NY, USA}\n}", 
 "linktypes" : ["Paper"],
 "links" : ["files/vanbaar11perceptually.pdf"]
},
{
 "title" : " Run-time Implementation of Modular Radiance Transfer", 
 "author" : ["Bradford Loos", "Lakulish Antani", "Kenny Mitchell", "Derek Nowrouzezahrai", "Wojciech Jarosz", "Peter-Pike Sloan"],
 "booktitle" : " ACM SIGGRAPH 2011 Talks", 
 "year" : 2011, 
 "thumbnail" : "images/mrt_icon.jpg", 
 "image" : "images/mrt_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "Real-time rendering of indirect lighting significantly enhances the sense of realism in video games. Unfortunately, previously including such effects often required time consuming scene dependent precomputation and heavy runtime computations unsuitable for low-end devices, such as mobile phones or game consoles. Modular Radiance Transfer (MRT) is a recent technique that computes approximate direct-to-indirect transfer by warping and combining light transport, in real-time, from a small library of simple shapes. This talk focusses on implementation issues of the MRT technical paper, including how our run time is designed to scale across many different platforms, from iPhones to modern GPUs. ",
  "bibtex": "@inproceedings{loos11runtime,\n    author = {Bradford J. Loos and Lakulish Antani and Kenny Mitchell and Derek Nowrouzezahrai and Wojciech Jarosz and Peter-Pike Sloan},\n    title = {Runtime Implementation of Modular Radiance Transfer},\n    booktitle = {ACM SIGGRAPH 2011 Talks},\n    series = {SIGGRAPH 2011},\n    year = {2011},\n    month = aug,\n    publisher = {ACM},\n    address = {New York, NY, USA},\n    location = {Vancouver, Canada}\n}", 
 "linktypes" : ["Sketch", "Video"],
 "links" : ["files/MRT%20Siggraph%202011%20Sketch.zip", "files/mrt.mp4"]
},
{
 "title" : " Light Factorization for Mixed-Frequency Shadows in Augmented Reality", 
 "author" : ["Derek Nowrouzezahrai", "Stefan Geiger", "Kenny Mitchell", "Robert Sumner", "Wojciech Jarosz", "Markus Gross"],
 "booktitle" : " Symp. on Mixed &amp; Augmented Reality (*ISMAR*)", 
 "year" : 2011, 
 "thumbnail" : "images/arlens_icon.jpg", 
 "image" : "images/arlens_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "Integrating animated virtual objects with their surroundings for high-quality augmented reality requires both geometric and radiometric consistency. We focus on the latter of these problems and present an approach that captures and factorizes external lighting in a manner that allows for realistic relighting of both animated and static virtual objects. Our factorization facilitates a combination of hard and soft shadows, with high-performance, in a manner that is consistent with the surrounding scene lighting. ",
  "bibtex": "@inproceedings{nowrouzezahrai11light,\n    author = {Derek Nowrouzezahrai and Stefan Geiger and Kenny Mitchell and Robert Sumner and Wojciech Jarosz and Markus Gross},\n    title = {Light Factorization for Mixed-Frequency Shadows in Augmented Reality},\n    booktitle = {10th IEEE International Symposium on Mixed and Augmented Reality (Proceedings of ISMAR 2011)},\n    year = {2011},\n    month = oct,\n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/arlens.pdf", "files/arlens3.mp4"]
},
{
 "title" : " Modular Radiance Transfer", 
 "author" : ["Bradford Loos", "Lakulish Antani", "Kenny Mitchell", "Derek Nowrouzezahrai", "Wojciech Jarosz", "Peter-Pike Sloan"],
 "booktitle" : " ACM Transactions on Graphics (SIGGRAPH Asia)", 
 "year" : 2011, 
 "thumbnail" : "images/mrt2_icon.jpg", 
 "image" : "images/mrt2_teaser.jpg", 
 "additionalmarkup" : "<h3 style=color:red>Featured in Papers Fast Forward Video!</h3>", 
 "abstract" : "Many rendering algorithms willingly sacrifice accuracy, favoring plausible shading with high-performance. We present Modular Radiance Transfer (MRT), an approach for smooth, approximate direct-to-indirect transfer that scales from high-end GPUs to low-end mobile platforms. MRT eliminates scene-dependent precomputation by storing compact transport on simple shapes, akin to bounce cards used in film production. These shapes' modular transport can be instanced, warped and connected on-the-fly to yield approximate light transport in large scenes. We introduce a prior on incident lighting distributions and perform all computations in low-dimensional subspaces. An {implicit lighting environment} induced from the low-rank approximations is in turn used to model secondary effects, such as volumetric transport variation, higher-order irradiance, and transport through lightfields. MRT is a new approach to precomputed lighting that uses a novel low-dimensional subspace simulation of light transport to uniquely balance the need for high-performance and portable solutions, low memory usage, and fast authoring iteration. ",
  "bibtex": "@article{loos11modular,\n    author = {Bradford J. Loos and Lakulish Antani and Kenny Mitchell and Derek Nowrouzezahrai and Wojciech Jarosz and Peter-Pike Sloan},\n    title = {Modular Radiance Transfer},\n    journal = {ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH Asia 2011)},\n    volume = {30},\n    number = {6},\n    year = {2011},\n    month = dec,\n}", 
 "linktypes" : ["Paper", "Video", "YouTube)"],
 "links" : ["files/mrt.pdf", "files/mrt.mp4", "http://www.YouTube.com/watch?v=3Kyj3NJ1pjQ"]
},
{
 "title" : " Irradiance rigs (sketch)", 
 "author" : ["Hong Yuan", "Derek Nowrouzezahrai", "Peter-Pike Sloan"],
 "booktitle" : " ACM SIGGRAPH 2010 Talks", 
 "year" : 2010, 
 "thumbnail" : "images/rigs_icon.jpg", 
 "image" : "images/rigs_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "When precomputed lighting is generated for static scene elements, the incident illumination on dynamic objects must be computed in a manner that is efficient and that faithfully captures the near- and far-field variation of the environment's illumination. Depending on the relative size of dynamic objects, as well as the number of lights in the scene, previous approaches fail to adequately sample the incident lighting and/or fail to scale. We present a principled, error-driven approach for dynamically transitioning between near- and far-field lighting. A more accurate model for sampling near-field lighting for disk sources is introduced, as well as far-field sampling and interpolation schemes tailored to each dynamic object. Lastly, we apply a flexible reflectance model to the computed illumination. ",
  "bibtex": "@inproceedings{ YNS10, \nauthor = {Yuan, Hong and Nowrouzezahrai, Derek and Sloan, Peter-Pike}, \ntitle = {Irradiance rigs}, \nbooktitle = {ACM SIGGRAPH 2010 Talks}, \nseries = {SIGGRAPH 2010}, \nyear = {2010}, \nisbn = {978-1-4503-0394-1}, \nlocation = {Los Angeles, California}, \npages = {44:1--44:1}, \narticleno = {44}, \nnumpages = {1}, \nurl = {http://doi.acm.org/10.1145/1837026.1837084}, \ndoi = {http://doi.acm.org/10.1145/1837026.1837084}, \nacmid = {1837084}, \npublisher = {ACM}, \naddress = {New York, NY, USA}, \n}", 
 "linktypes" : ["Paper (ACM Portal)"],
 "links" : ["{{http://portal.acm.org/citation.cfm?id=1837084}}"]
},
{
 "title" : " A Comprehensive Theory of Volumetric Radiance Estimation using Photon Points and Beams", 
 "author" : ["Wojciech Jarosz", "Derek Nowrouzezahrai", "Iman Sadeghi", "Henrik Wann Jensen"],
 "booktitle" : " ACM Transactions on Graphics (Presented at *SIGGRAPH*)", 
 "year" : 2010, 
 "thumbnail" : "images/beams_icon.jpg", 
 "image" : "images/beams_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "We present two contributions to the area of volumetric rendering. We develop a novel, comprehensive theory of volumetric radiance estimation that leads to several new insights and includes all previously published estimates as special cases. This theory allows for estimating in-scattered radiance at a point, or accumulated radiance along a camera ray, with the standard photon particle representation used in previous work. Furthermore, we generalize these operations to include a more compact, and more expressive intermediate representation of lighting in participating media, which we call ``photon beams.'' The combination of these representations and their respective query operations results in a collection of nine distinct volumetric radiance estimates. Our second contribution is a more efficient rendering method for participating media based on photon beams. Even when shooting and storing less photons and using less computation time, our method significantly reduces both bias (blur) and variance in volumetric radiance estimation. This enables us to render sharp lighting details (e.g. volume caustics) using just tens of thousands of photon beams, instead of the millions to billions of photon points required with previous methods. ",
  "bibtex": "@article{ JNSJ11,\n author = {Jarosz, Wojciech and Nowrouzezahrai, Derek and Sadeghi, Iman and Jensen, Henrik Wann}, \n title = {A Comprehensive Theory of Volumetric Radiance Estimation using Photon Points and Beams}, \n journal = {ACM Transactions on Graphics (Presented at SIGGRAPH 2011)}, \n month = jan, \n year = {2011}, \n publisher = {ACM}, \n address = {New York, NY, USA},\n  }", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/jarosz11comprehensive.pdf", "files/jarosz11comprehensive.mov"]
},
{
 "title" : " Fast Global Illumination on Dynamic Height Fields", 
 "author" : ["Derek Nowrouzezahrai", "John Snyder"],
 "booktitle" : " Eurographics Symposium on Rendering (*EGSR*)", 
 "year" : 2009, 
 "thumbnail" : "images/HFGI_icon.jpg", 
 "image" : "images/HFGI_teaser.jpg", 
 "additionalmarkup" : "<h3 style=color:red>Featured on Proceedings Back Cover!</h3>", 
 "abstract" : "We present a real-time method for rendering global illumination effects from large area and environmental lights on dynamic height fields. In contrast to previous work, our method handles inter-reflections (indirect lighting) and non-diffuse surfaces. To reduce sampling, we construct one multi-resolution pyramid for height variation to compute direct shadows, and another pyramid for each indirect bounce of incident radiance to compute interreflections. The basic principle is to sample the points blocking direct light, or shedding indirect light, from coarser levels of the pyramid the farther away they are from a given receiver point. We unify the representation of visibility and indirect radiance at discrete azimuthal directions (i.e., as a function of a single elevation angle) using the concept of a casting set of visible points along this direction whose contributions are collected in the basis of normalized Legendre polynomials. This analytic representation is compact, requires no precomputation, and allows efficient integration to produce the spherical visibility and indirect radiance signals. Sub-sampling visibility and indirect radiance, while shading with full-resolution surface normals, further increases performance without introducing noticeable artifacts. Our method renders 512x512 height fields (>500K triangles) at 36Hz. ",
  "bibtex": "@article{ NS09, \ntitle = {Fast Global Illumination on Dynamic Height Fields}, \nauthor = {Derek Nowrouzezahrai and John Snyder}, \njournal = {Computer Graphics Forum: Eurographics Symposium on Rendering}, \nyear = {2009}, \nmonth = jun, \n}", 
 "linktypes" : ["Paper", "Video", "Slides", "Supplement"],
 "links" : ["files/paper1086_final.pdf", "files/EGSR09_final_video_xvid.avi", "files/hfindirect_egsr09.ppt", "files/hfindirect_supplement.pdf"]
},
{
 "title" : " Data-driven curvature for real-time line drawing of dynamic scenes", 
 "author" : ["Evangelos Kalogerakis", "Derek Nowrouzezahrai", "Patricio Simari", "James McCrae", "Aaron Hertzmann", "Karan Singh"],
 "booktitle" : " ACM Transactions on Graphics (Presented at *SIGGRAPH*)", 
 "year" : 2009, 
 "thumbnail" : "images/ddcurvature_icon.jpg", 
 "image" : "images/ddcurvature_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "This paper presents a method for real-time line drawing of deforming objects. Object-space line drawing algorithms for many types of curves, including suggestive contours, highlights, ridges and valleys, rely on surface curvature and curvature derivatives. Unfortunately, these curvatures and their derivatives cannot be computed in real-time for animated, deforming objects. In a preprocessing step, our method learns the mapping from a low-dimensional set of animation parameters (e.g., joint angles) to surface curvatures for a deforming 3D mesh. The learned model can then accurately and efficiently predict curvatures and their derivatives, enabling real-time object-space rendering of suggestive contours and other such curves. This represents an order-of-magnitude speed-up over the fastest existing algorithm capable of estimating curvatures and their derivatives accurately enough for many different types of line drawings. The learned model can generalize to novel animation sequences, and is also very compact, typically requiring a few megabytes of storage at run-time. We demonstrate our method for various types of animated objects, including skeleton-based characters, cloth simulation and blend-shape facial animation, using a variety of non-photorealistic rendering styles.An important component of our system is the use of dimensionality reduction for differential mesh data. ",
  "bibtex": "@article{ KNSMHS09, \nauthor = {Kalogerakis, Evangelos and Nowrouzezahrai, Derek and Simari, Patricio and Mccrae, James and Hertzmann, Aaron and Singh, Karan}, \ntitle = {Data-driven curvature for real-time line drawing of dynamic scenes}, \njournal = {ACM Transactions on Graphics (Presented at SIGGRAPH 2009)}, \nvolume = {28}, \nnumber = {1}, \nmonth = may, \nyear = {2009}, \nissn = {0730-0301}, \npages = {1--13}, \npublisher = {ACM}, \naddress = {New York, NY, USA}, \n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/ddcurvature.pdf", "files/ddcurvature.avi"]
},
{
 "title" : " Shadowing Dynamic Scenes with Arbitrary BRDFs", 
 "author" : ["Derek Nowrouzezahrai", "Evangelos Kalogerakis", "Eugene Fiume"],
 "booktitle" : " Eurographics", 
 "year" : 2009, 
 "thumbnail" : "images/dynprt09_icon.jpg", 
 "image" : "images/dynprt09_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "We present a real-time relighting and shadowing method for dynamic scenes with varying lighting, view and BRDFs. Our approach is based on a compact representation of reflectance data that allows for changing the BRDF at run-time and a data-driven method for accurately synthesizing self-shadows on articulated and deformable geometries. Unlike previous self-shadowing approaches, we do not rely on local blocking heuristics. We do not fit a model to the BRDF-weighted visibility, but rather only to the visibility that changes during animation. In this manner, our model is more compact than previous techniques and requires less computation both during fitting and at run-time. Our reflectance product operators can re-integrate arbitrary low-frequency view-dependent BRDF effects on-the-fly and are compatible with all previous dynamic visibility generation techniques as well as our own data-driven visibility model. We apply our reflectance product operators to three different visibility generation models, and our data-driven model can achieve framerates well over 300Hz. ",
  "bibtex": "@article{ NKF09, \nauthor = {Nowrouzezahrai, Derek and Kalogerakis, Evangelos and Fiume, Eugene}, \ntitle = {Shadowing Dynamic Scenes with Arbitrary BRDFs}, \njournal = {Computer Graphics Forum: Eurographics Conference}, \nvolume = {28}, \nyear = {2009}, \nmonth = apr, \npages = {249-258(10)}, \n}", 
 "linktypes" : ["Paper", "Video"],
 "links" : ["files/DynamicArbitraryBRDF.pdf", "files/EG_submission1057_XVID.avi"]
},
{
 "title" : " Robust statistical estimation of curvature on discretized surfaces", 
 "author" : ["Evangelos Kalogerakis", "Patricio Simari", "Derek Nowrouzezahrai", "Karan Singh"],
 "booktitle" : " Eurographics Symposium on Geometry Processing (*SGP*)", 
 "year" : 2009, 
 "thumbnail" : "images/sgp07_icon.jpg", 
 "image" : "images/sgp07_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "A robust statistics approach to curvature estimation on discretely sampled surfaces, namely polygon meshes and point clouds, is presented. The method exhibits accuracy, stability and consistency even for noisy, non-uniformly sampled surfaces with irregular configurations. Within an M-estimation framework, the algorithm is able to reject noise and structured outliers by sampling normal variations in an adaptively reweighted neighborhood around each point. The algorithm can be used to reliably derive higher order differential attributes and even correct noisy surface normals while preserving the fine features of the normal and curvature field. The approach is compared with state-of-the-art curvature estimation methods and shown to improve accuracy by up to an order of magnitude across ground truth test surfaces under varying tessellation densities and types as well as increasing degrees of noise. Finally, the benefits of a robust statistical estimation of curvature are illustrated by applying it to the popular applications of mesh segmentation and suggestive contour rendering. ",
  "bibtex": "@inproceedings{ KSNS07, \nauthor = {Kalogerakis, Evangelos and Simari, Patricio and Nowrouzezahrai, Derek and Singh, Karan}, \ntitle = {Robust statistical estimation of curvature on discretized surfaces}, \nbooktitle = {Computer Graphics Forum: Eurographics Symposium on Geometry Processing}, \nyear = {2007}, \nisbn = {978-3-905673-46-3}, \npages = {13--22}, \nmonth = jan, \nlocation = {Barcelona, Spain}, \npublisher = {Eurographics Association}, \naddress = {Aire-la-Ville, Switzerland, Switzerland}, \n}", 
 "linktypes" : ["Paper"],
 "links" : ["files/CurvatureSGP.pdf"]
},
{
 "title" : " Multi-objective shape segmentation and labeling", 
 "author" : ["Patricio Simari", "Derek Nowrouzezahrai", "Evangelos Kalogerakis", "Karan Singh"],
 "booktitle" : " Eurographics Symposium on Geometry Processing (*SGP*)", 
 "year" : 2009, 
 "thumbnail" : "images/sgp09_icon.jpg", 
 "image" : "images/sgp09_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "Shape segmentations designed for different applications show significant variation in the composition of their parts. In this paper, we introduce the segmentation and labeling of shape based on the optimization of multiple objectives that capture application-specific segmentation criteria. We present a number of efficient objective functions that capture useful shape adjectives (compact, flat, narrow, perpendicular, etc.) Segmentation descriptions within our framework combine multiple such objective functions with optional labels to define each part. The optimization problem is simplified by proposing weighted Voronoi partitioning as a compact and continuous parameterization of spatially embedded shape segmentations. Separation of spatially close but geodesically distant parts is made possible using multi-dimensional scaling (MDS) prior to Voronoi partitioning. Optimization begins with an initial segmentation found using the centroids of a k-means clustering of surface elements. This partition is automatically labeled to optimize heterogeneous part objectives and the Voronoi centers and their weights optimized using Generalized Pattern Search (GPS). We illustrate our framework using several diverse segmentation applications: consistent segmentations with semantic labels, bounding volume hierarchies for path tracing, and automatic rig and clothing transfer between animation characters. ",
  "bibtex": "@inproceedings{ SNKS09, \nauthor = {Simari, Patricio and Nowrouzezahrai, Derek and Kalogerakis, Evangelos and Singh, Karan}, \ntitle = {Multi-objective shape segmentation and labeling}, \nbooktitle = {Computer Graphics Forum: Eurographics Symposium on Geometry Processing}, \nyear = {2009}, \nmonth = mar, \nlocation = {Munich, Germany}, \npublisher = {Eurographics Association}, \naddress = {Aire-la-Ville, Switzerland, Switzerland}, \n}", 
 "linktypes" : ["Paper", "Video (AVI)"],
 "links" : ["files/multiobjectivesegmentation_sgp.pdf", "files/multiobjectivesegmentation_sgp.avi"]
},
{
 "title" : " Extracting lines of curvature from noisy point clouds", 
 "author" : ["Evangelos Kalogerakis", "Derek Nowrouzezahrai", "Patricio Simari", "Karan Singh"],
 "booktitle" : " Journal of Computer Aided Design (*CAD*)", 
 "year" : 2009, 
 "thumbnail" : "images/cad09_icon.jpg", 
 "image" : "images/cad09_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "We present a robust framework for extracting lines of curvature from point clouds. First, we show a novel approach to denoising the input point cloud using robust statistical estimates of surface normal and curvature which automatically rejects outliers and corrects points by energy minimization. Then the lines of curvature are constructed on the point cloud with controllable density. Our approach is applicable to surfaces of arbitrary genus, with or without boundaries, and is statistically robust to noise and outliers while preserving sharp surface features. We show our approach to be effective over a range of synthetic and real-world input datasets with varying amounts of noise and outliers. The extraction of curvature information can benefit many applications in CAD, computer vision and graphics for point cloud shape analysis, recognition and segmentation. Here, we show the possibility of using the lines of curvature for feature-preserving mesh construction directly from noisy point clouds. ",
  "bibtex": "@article{ KNSS09, \nauthor = {Kalogerakis, Evangelos and Nowrouzezahrai, Derek and Simari, Patricio and Singh, Karan}, \ntitle = {Extracting lines of curvature from noisy point clouds}, \njournal = {Computer Aided Design}, \nvolume = {41}, \nnumber = {4}, \nyear = {2009}, \nmonth = jan, \nissn = {0010-4485}, \npages = {282--292}, \ndoi = {http://dx.doi.org/10.1016/j.cad.2008.12.004}, \npublisher = {Butterworth-Heinemann}, \naddress = {Newton, MA, USA}, \n}", 
 "linktypes" : ["Paper", "Code"],
 "links" : ["files/CurvatureCAD.pdf", "files/robust_curvature.zip"]
},
{
 "title" : " Video Browsing by Direct Manipulation", 
 "author" : ["Pierre Dragicevic", "Gonzalo Ramos", "Jacobo Bibliowicz", "Derek Nowrouzezahrai", "Ravin Balakrishnan", "Karan Singh"],
 "booktitle" : " Proceeding of the 26th annual conference on Human factors in computing systems (*SIGCHI*)", 
 "year" : 2008, 
 "thumbnail" : "images/dimp_icon.jpg", 
 "image" : "images/dimp_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "We present a method for browsing videos by directly dragging their content. This method brings the benefits of direct manipulation to an activity typically mediated by widgets. We support this new type of interactivity by: 1) automatically extracting motion data from videos; and 2) a new technique called relative flow dragging that lets users control video playback by moving objects of interest along their visual trajectory. We show that this method can outperform the traditional seeker bar in video browsing tasks that focus on visual content rather than time. ",
  "bibtex": "@inproceedings{ DGBNBS08, \naddress = {New York, NY, USA}, \nauthor = {Dragicevic, Pierre and Ramos, Gonzalo and Bibliowicz, Jacobo and Nowrouzezahrai, Derek and Balakrishnan, Ravin and Singh, Karan}, \nbooktitle = {CHI '08: Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems}, \nciteulike-article-id = {2686441}, \nciteulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1357054.1357096}, \nciteulike-linkout-1 = {http://dx.doi.org/10.1145/1357054.1357096}, \ndoi = {10.1145/1357054.1357096}, \nisbn = {9781605580111}, \nkeywords = {motion estimation, navigation, object recognition, user interface}, \npages = {237--246}, \nposted-at = {2009-04-28 14:26:17}, \npriority = {0}, \npublisher = {ACM}, \ntitle = {Video browsing by direct manipulation}, \nyear = {2008}, \n}", 
 "linktypes" : ["Paper", "Video", "Video (short)"],
 "links" : ["files/dimp-chi08.pdf", "files/dimp-long.avi", "files/dimp-short.avi"]
},
{
 "title" : " Shadowed Relighting of Dynamic Geometry with 1D BRDFs", 
 "author" : ["Derek Nowrouzezahrai", "Evangelos Kalogerakis", "Patricio Simari", "Eugene Fiume"],
 "booktitle" : " Eurographics Short Paper", 
 "year" : 2008, 
 "thumbnail" : "images/eurographics08_icon.jpg", 
 "image" : "images/eurographics08_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "We present a method for synthesizing the dynamic self-occlusion of an articulating character in real-time (> 170Hz) while incorporating reflection effects from 1D BRDFs under dynamic lighting and view conditions. We introduce and derive a general operator form for convolving spherical harmonics (SH) occlusion vectors with arbitrary 1D BRDF kernels. This operator, coupled with a compact linear model for predicting SH occlusion over articulating meshes, segments the BRDF and visibility terms of the direct illumination integral. We illustrate our results on a thin-membrane translucency model and the normalized Phong BRDF. ",
  "bibtex": "@article{ NKSF08, \nauthor = {Nowrouzezahrai, Derek and Kalogerakis, Evangelos and Simari, Patricio and Fiume, Eugene}, \ntitle = {Shadowed Relighting of Dynamic Geometry with 1D BRDFs}, \njournal = {Proceedings of Eurographics Short Papers}, \nmonth = jan, \nyear = {2008}, \n}", 
 "linktypes" : ["Video (AVI)"],
 "links" : ["files/ZHPhong-divx.avi"]
},
{
 "title" : " Solving Radiance Transport as a Differential Equation", 
 "author" : ["Derek Nowrouzezahrai", "Chris Gonterman"],
 "booktitle" : " Department of Computer Science Tech Report CSRG-588 - University of Toronto", 
 "year" : 2008, 
 "thumbnail" : "images/image018_icon.jpg", 
 "image" : "images/image018_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "We introduce an alternative to Monte-Carlo techniques for solving radiance transport problems for participating media. We use a reformulation of the volume rendering equation from its standard integro-differential form to a purely differential form. We then leverage the large body of work in numerical methods for solving differential equations by framing and analyzing the problem as a differential equation. To our knowledge, this is the first application of such techniques in the area of photo-realistic rendering of volumes based on ray optics. ",
  "bibtex": "@techreport{ NG08tr, \nauthor = {Derek Nowrouzezahrai and Chris Gonterman}, \ntitle = {Solving Radiance Transport as a Differential Equation}, \nnumber = {CSRG-588}, \ninstitution = {Department of Computer Science, University of Toronto}, \naddress = {Toronto, Canada}, \nmonth = dec, \nyear = {2008}, \n}", 
 "linktypes" : [],
 "links" : []
},
{
 "title" : " Fast Soft Self-Shadowing on Dynamic Height Fields", 
 "author" : ["John Snyder", "Derek Nowrouzezahrai"],
 "booktitle" : " Eurographics Symposium on Rendering (*EGSR*)", 
 "year" : 2008, 
 "thumbnail" : "images/HF_icon.jpg", 
 "image" : "images/HF_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "We present a new, real-time method for rendering soft shadows from large light sources or lighting environments on dynamic height fields. The method first computes a horizon map for a set of azimuthal directions. To reduce sampling, we compute a multi-resolution pyramid on the height field. Coarser pyramid levels are indexed as the distance from caster to receiver increases. For every receiver point and every azimuthal direction, a smooth function of blocking angle in terms of log distance is reconstructed from a height difference sample at each pyramid level. This function's maximum approximates the horizon angle. We then sum visibility at each receiver point over wedges determined by successive pairs of horizon angles. Each wedge represents a linear transition in blocking angle over its azimuthal extent. It is precomputed in the order-4 spherical harmonic (SH) basis, for a canonical azimuthal origin and fixed extent, resulting in a 2D table. The SH triple product of 16D vectors representing lighting, total visibility, and diffuse reflectance then yields the soft-shadowed result. Two types of light sources are considered; both are distant and low-frequency. Environmental lights require visibility sampling around the complete 360 degree azimuth, while key lights sample visibility within a partial swath. Restricting the swath concentrates samples where the light comes from (e.g. 3 azimuthal directions vs. 16-32 for a full swath) and obtains sharper shadows. Our GPU implementation handles height fields up to 1024x1024 in real-time. The computation is simple, local, and parallel, with performance independent of geometric content. ",
  "bibtex": "@article{ SN08, \ntitle = {Fast Soft Self-Shadowing on Dynamic Height Fields}, \nauthor = {John Snyder and Derek Nowrouzezahrai}, \njournal = {Computer Graphics Forum: Eurographics Symposium on Rendering}, \nvolume = {27}, \nnumber = {4}, \nmonth = jun, \nyear = {2008}, \npages = {1275--1283}, \n}", 
 "linktypes" : ["Paper", "Video", "Slides"],
 "links" : ["files/hfvisib.pdf", "files/hfvisib.wmv", "files/hfvisib.ppt"]
},
{
 "title" : " Image-Based Proxy Accumulation for Real-Time Soft Global Illumination", 
 "author" : ["Peter-Pike Sloan", "Naga K. Govindaraju", "Derek Nowrouzezahrai", "John Snyder"],
 "booktitle" : " Pacific Conference on Computer Graphics and Applications (*PG*)", 
 "year" : 2007, 
 "thumbnail" : "images/PGSplat_icon.jpg", 
 "image" : "images/PGSplat_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "We present a new, general, and real-time technique for soft global illumination in low-frequency environmental lighting. It accumulates over relatively few spherical proxies which  approximate the light blocking and re-radiating effect of dynamic geometry. Soft shadows are computed by accumulating log visibility vectors for each sphere proxy as seen by each receiver point. Inter-reflections are computed by accumulating vectors representing the proxy's unshadowed radiance when illuminated by the environment. Both vectors capture low-frequency directional dependence using the spherical harmonic basis. We also present a new proxy accumulation strategy that splats each proxy to receiver pixels in image space to collect its shadowing and indirect lighting contribution. Our soft GI rendering pipeline unifies direct and indirect soft effects with a simple accumulation strategy that maps entirely to the GPU and outperforms previous vertex-based methods. ",
  "bibtex": "@article{ SGNS07, \nauthor = {Peter-Pike Sloan and Naga K. Govindaraju and Derek Nowrouzezahrai and John Snyder}, \ntitle = {Image-Based Proxy Accumulation for Real-Time Soft Global Illumination}, \njournal = {Pacific Conference on Computer Graphics and Applications}, \nvolume = {0}, \nyear = {2007}, \nmonth = jan, \nissn = {1550-4085}, \npages = {97-105}, \ndoi = {http://doi.ieeecomputersociety.org/10.1109/PG.2007.28}, \npublisher = {IEEE Computer Society}, \naddress = {Los Alamitos, CA, USA}, \n}", 
 "linktypes" : ["Paper", "Slides", "Video Clips 1", "2"],
 "links" : ["files/ProxyPG.pdf", "files/imacc.pptx", "files/imacc_movies.zip", "files/imacc_talk_movies.zip"]
},
{
 "title" : " Eigentransport for efficient and accurate all-frequency relighting", 
 "author" : ["Derek Nowrouzezahrai", "Patricio Simari", "Evangelos Kalogerakis", "Eugene Fiume"],
 "booktitle" : " GRAPHITE", 
 "year" : 2007, 
 "thumbnail" : "images/eigentransport_icon.jpg", 
 "image" : "images/eigentransport_teaser.jpg", 
 "additionalmarkup" : "<h3 style=color:red>Winner: Best paper award!</h3>", 
 "abstract" : "We present a method for creating a geometry-dependent basis for diffuse precomputed radiance transfer. Unlike previous PRT bases, ours is derived from Principal Component Analysis of the sampled transport functions at each vertex, without relying on pre-projections to secondary bases, such as the Spherical Harmonics or Haar wavelets. It allows for efficient evaluation of shading, has low memory requirements and produces accurate results with few coefficients. We are able to capture all-frequency effects from both distant and near-field dynamic lighting in real-time and present a simple and efficient rotation scheme. Reconstruction of the final shading becomes a low-order dot product and is performed on the GPU. ",
  "bibtex": "@inproceedings{ NSKF07, \nauthor = {Nowrouzezahrai, Derek and Simari, Patricio and Kalogerakis, Evangelos and Fiume, Eugene}, \ntitle = {Eigentransport for efficient and accurate all-frequency relighting}, \nbooktitle = {GRAPHITE '07: Proceedings of the 5th international conference on Computer graphics and interactive techniques in Australia and Southeast Asia}, \nyear = {2007}, \nmonth = jan, \nisbn = {978-1-59593-912-8}, \npages = {163--169}, \nlocation = {Perth, Australia}, \ndoi = {http://doi.acm.org/10.1145/1321261.1321290}, \npublisher = {ACM}, \naddress = {New York, NY, USA}, \n}", 
 "linktypes" : ["Paper", "Slides"],
 "links" : ["files/GeometryDependentPRT_graphite.pdf", "files/EigentransportGraphite.pdf"]
},
{
 "title" : " Compact and efficient generation of radiance transfer for dynamically articulated characters", 
 "author" : ["Derek Nowrouzezahrai", "Patricio Simari", "Evangelos Kalogerakis", "Karan Singh", "Eugene Fiume"],
 "booktitle" : " GRAPHITE", 
 "year" : 2007, 
 "thumbnail" : "images/dynprt07_icon.jpg", 
 "image" : "images/dynprt07_teaser.gif", 
 "additionalmarkup" : "", 
 "abstract" : "We present a data-driven technique for generating the precomputed radiance transfer vectors of an animated character as a function of its joint angles. We learn a linear model for generating real-time lighting effects on articulated characters while capturing soft self shadows caused by dynamic distant lighting. Indirect illumination can also be reproduced using our framework. Previous data-driven techniques have either restricted the type of lighting response (generating only ambient occlusion), the type of animated sequences (response functions to external forces) or have complicated runtime algorithms and incur non-trivial memory costs. We provide insights into the dimensionality reduction of the pose and coefficient spaces. Our model can be fit quickly as a preprocess, is very compact (~1MB) and runtime transfer vectors are generated using a simple algorithm in real-time (>100 Hz using a CPU-only implementation.) We can reproduce lighting effects on hundreds of trained poses using less memory than required to store a single mesh's PRT coefficients. Moreover, our model extrapolates to produce smooth, believable lighting results on novel poses and our method can be easily integrated into existing interactive content pipelines. ",
  "bibtex": "@inproceedings{ NSKSF07, \nauthor = {Nowrouzezahrai, Derek and Simari, Patricio and Kalogerakis, Evangelos and Singh, Karan and Fiume, Eugene}, \ntitle = {Compact and efficient generation of radiance transfer for dynamically articulated characters}, \nbooktitle = {GRAPHITE '07: Proceedings of the 5th international conference on Computer graphics and interactive techniques in Australia and Southeast Asia}, \nyear = {2007}, \nmonth = jan, \nisbn = {978-1-59593-912-8}, \npages = {147--154}, \nlocation = {Perth, Australia}, \ndoi = {http://doi.acm.org/10.1145/1321261.1321288}, \npublisher = {ACM}, \naddress = {New York, NY, USA}, \n}", 
 "linktypes" : ["Paper", "Slides"],
 "links" : ["files/DataDrivenPRT_graphite_paper.pdf", "files/ArticulatedShadowingGraphite.pdf"]
},
{
 "title" : " A controllable, fast and stable basis for vortex based smoke simulation", 
 "author" : ["Alexis Angelidis", "Fabrice Neyret", "Karan Singh", "Derek Nowrouzezahrai"],
 "booktitle" : " Eurographics Symposium on Computer Animation (*SCA*)", 
 "year" : 2006, 
 "thumbnail" : "images/sca06_icon.jpg", 
 "image" : "images/sca06_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "We introduce a novel method for describing and controlling a 3D smoke simulation. Using harmonic analysis and principal component analysis, we define an underlying description of the fluid flow that is compact and meaningful to non-expert users. The motion of the smoke can be modified with high level tools, such as animated current curves, attractors and tornadoes. Our simulation is controllable, interactive and stable for arbitrarily long periods of time. The simulation's computational cost increases linearly in the number of motion samples and smoke particles. Our adaptive smoke particle representation conveniently incorporates the surface-like characteristics of real smoke. ",
  "bibtex": "@inproceedings{ ANSN06, \nauthor = {Angelidis, Alexis and Neyret, Fabrice and Singh, Karan and Nowrouzezahrai, Derek}, \ntitle = {A controllable, fast and stable basis for vortex based smoke simulation}, \nbooktitle = {SCA '06: Proceedings of the 2006 ACM SIGGRAPH/Eurographics symposium on Computer animation}, \nyear = {2006}, \nmonth = jan, \nisbn = {3-905673-34-7}, \npages = {25--32}, \nlocation = {Vienna, Austria}, \npublisher = {Eurographics Association}, \naddress = {Aire-la-Ville, Switzerland, Switzerland}, \n}", 
 "linktypes" : ["Paper (ACM Portal)"],
 "links" : ["{{http://portal.acm.org/citation.cfm?id=1218068}}"]
},
{
 "title" : " GPU-accelerated ray casting of node-based implicits", 
 "author" : ["Christian Lessig", "Derek Nowrouzezahrai", "Karan Singh"],
 "booktitle" : " ACM SIGGRAPH 2006 Research posters", 
 "year" : 2006, 
 "thumbnail" : "images/raycastimplicits_icon.jpg", 
 "image" : "images/raycastimplicits_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "We demonstrate that state-of-the-art GPUs are well suited for the visualization of node-based implicit surfaces that are the natural surface representation for Lagrangian simulations which are used for example for the simulation of fluids. ",
  "bibtex": "@inproceedings{ LNS06, \nauthor = {Lessig, Christian and Nowrouzezahrai, Derek and Singh, Karan}, \ntitle = {GPU-accelerated ray casting of node-based implicits}, \nbooktitle = {ACM SIGGRAPH 2006 Research posters}, \nyear = {2006}, \nmonth = jan, \nisbn = {1-59593-364-6}, \npages = {54}, \nlocation = {Boston, Massachusetts}, \ndoi = {http://doi.acm.org/10.1145/1179622.1179684}, \npublisher = {ACM}, \naddress = {New York, NY, USA}, \n}", 
 "linktypes" : ["Poster", "Video"],
 "links" : ["files/sulam_poster.pdf", "files/sulam_video.mov"]
},
{
 "title" : " Vortex Based Smoke Simulation and Control", 
 "author" : ["Derek Nowrouzezahrai"],
 "booktitle" : " Master Thesis - University of Toronto", 
 "year" : 2006, 
 "thumbnail" : "images/msc_icon.jpg", 
 "image" : "images/sca06_teaser.jpg", 
 "additionalmarkup" : "", 
 "abstract" : "This thesis is an extension of our work published at the Symposium of Computer Animation with additional investigations on the performance benefits of a parallelized GPU implementation of the work, including a full re-implementation of the GPU framework. ",
  "bibtex": "@mastersthesis{ NowrouzezahraiMScThesis, \nauthor = {Derek Nowrouzezahrai}, \ntitle = {{Vortex Based Smoke Simulation and Control}}, \nschool = {University of Toronto}, \naddress = {Toronto, Canada}, \nyear = {2006}, \nmonth = oct, \n}", 
 "linktypes" : ["Master's Thesis"],
 "links" : ["files/Derek_MSc_Thesis.pdf"]
},
{
 "title" : " High-Performance Double-Precision Cosine Generation", 
 "author" : ["Derek Nowrouzezahrai", "Brian Decker", "William Bishop"],
 "booktitle" : " International Conference on Computer Design", 
 "year" : 2005, 
 "thumbnail" : "images/cosine05_icon.jpg", 
 "image" : "images/cosine05_teaser.png", 
 "additionalmarkup" : "", 
 "abstract" : "The trigonometric cosine function plays an important role in communication systems, digital signal processing systems, and graphical systems. This paper presents a technique for generating the cosine of an angle that is more computationally efficient than the CORDIC algorithm and its many variants for double-precision floating point calculations. A hardware design implementation of the cosine generator has been developed. Simulation results for an Altera Stratix II FPGA implementation indicate that the hardware design is both more efficient and more precise than previous published implementations. ",
  "bibtex": "@article{ NDB05, \nauthor = {Nowrouzezahrai, Derek and Decker, Brian and Bishop, William}, \ntitle = {High-Performance Double-Precision Cosine Generation}, \njournal = {Proceedings of the 2005 International Conference on Computer Design}, \nmonth = jun, \nyear = {2005}, \n}", 
 "linktypes" : ["Paper"],
 "links" : ["files/cosine_report.pdf"]
}
]